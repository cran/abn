
R Under development (unstable) (2021-03-25 r80120) -- "Unsuffered Consequences"
Copyright (C) 2021 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> pkgname <- "abn"
> source(file.path(R.home("share"), "R", "examples-header.R"))
> options(warn = 1)
> library('abn')
Loading required package: nnet
Loading required package: lme4
Loading required package: Matrix
Loading required package: Rgraphviz
Loading required package: graph
Loading required package: BiocGenerics
Loading required package: parallel

Attaching package: ‘BiocGenerics’

The following objects are masked from ‘package:parallel’:

    clusterApply, clusterApplyLB, clusterCall, clusterEvalQ,
    clusterExport, clusterMap, parApply, parCapply, parLapply,
    parLapplyLB, parRapply, parSapply, parSapplyLB

The following objects are masked from ‘package:stats’:

    IQR, mad, sd, var, xtabs

The following objects are masked from ‘package:base’:

    Filter, Find, Map, Position, Reduce, anyDuplicated, append,
    as.data.frame, basename, cbind, colnames, dirname, do.call,
    duplicated, eval, evalq, get, grep, grepl, intersect, is.unsorted,
    lapply, mapply, match, mget, order, paste, pmax, pmax.int, pmin,
    pmin.int, rank, rbind, rownames, sapply, setdiff, sort, table,
    tapply, union, unique, unsplit, which.max, which.min

Loading required package: grid
> 
> base::assign(".oldSearch", base::search(), pos = 'CheckExEnv')
> base::assign(".old_wd", base::getwd(), pos = 'CheckExEnv')
> cleanEx()
> nameEx("abn-package")
> ### * abn-package
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: . abn .
> ### Title: abn Package
> ### Aliases: overview abn abn-package
> ### Keywords: documentation package
> 
> ### ** Examples
> 
> ## Citations:
> print(citation('abn'), bibtex=TRUE)

To cite `abn` modelling approach and `abn` package in publication use,
select the most appropriate among:

--------------------------------------------------------------------------------------------------------

To cite use of the Bayesian and MLE implementation of `abn` in
publications use:

  Kratzer, G., Lewis, F.I., Comin, A., Pittavino, M. and Furrer, R.
  (2019). Additive Bayesian Network Modelling with the R Package abn.
  arXiv preprint arXiv:1911.09006

A BibTeX entry for LaTeX users is

  @Article{,
    title = {Additive {B}ayesian Network Modelling with the {R} Package {abn}},
    author = {Gilles Kratzer and Fraser Iain Lewis and Arianna Comin and Marta Pittavino and Reinhard Furrer},
    year = {2019},
    journal = {arXiv preprint arXiv:1911.09006},
  }

To cite an example of a typical ABN analysis in publications use:

  Kratzer, G. and Lewis, F.I. and Willi, B. and Meli, M.L. and Boretti,
  F.S. and Hofmann-Lehmann, R. and Torgerson, P. and Furrer, R. and
  Hartnack, S. (2020). Bayesian Network Modeling Applied to Feline
  Calicivirus Infection Among Cats in Switzerland. Frontiers in
  Veterinary Science, 7,73

A BibTeX entry for LaTeX users is

  @Article{,
    title = {{B}ayesian {N}etwork {M}odeling {A}pplied to {F}eline {C}alicivirus {I}nfection {A}mong {C}ats in {S}witzerland},
    author = {Gilles Kratzer and Fraser Iain Lewis and Barbara Willi and Marina Meli and Felicitas Boretti and Regina Hofmann-Lehmann and Paul Torgerson and Reinhard Furrer and Sonja Hartnack},
    year = {2020},
    journal = {Frontiers in Veterinary Science},
  }

To cite use of `abn` underlaying methodology in applied research for
publications use:

  Lewis, F. I., & Ward, M. P. (2013). Improving epidemiologic data
  analyses through multivariate regression modelling. Emerging themes
  in epidemiology, 10(1), 4.

A BibTeX entry for LaTeX users is

  @Article{,
    title = {Improving epidemiologic data analyses through multivariate regression modelling},
    author = {Lewis Fraser Iain and Ward Michael P},
    journal = {Emerging themes in epidemiology},
    volume = {10},
    number = {1},
    pages = {4},
    year = {2013},
    publisher = {BioMed Central},
  }

To cite use of the R package `abn` in publications use:

  Kratzer, G. , Pittavino, M, Lewis, F.I. and Furrer, R. (2020). abn:
  an R package for modelling multivariate data using additive Bayesian
  networks. R package version 2.4.
  https://CRAN.R-project.org/package=abn

A BibTeX entry for LaTeX users is

  @Manual{,
    title = {abn: an {R} package for modelling multivariate data using additive {B}ayesian networks},
    author = {Gilles Kratzer and Marta Pittavino and Fraser Iain Lewis and Reinhard Furrer},
    year = {2020},
    note = {R package version 2.4},
    url = {https://CRAN.R-project.org/package=abn},
  }

> 
> 
> ## Installing the R package Rgraphviz:
> # if (!requireNamespace("BiocManager", quietly = TRUE))
> #     install.packages("BiocManager")
> # BiocManager::install("Rgraphviz")
> 
> ## README.md in the directory `bootstrapping_example/`:
> # edit(file=paste0( path.package('abn'),'/bootstrapping_example/README.md'))
> 
> 
> 
> cleanEx()
> nameEx("build_score_cache")
> ### * build_score_cache
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: buildScoreCache
> ### Title: Build a cache of goodness of fit metrics for each node in a DAG,
> ###   possibly subject to user-defined restrictions
> ### Aliases: buildScoreCache
> ### Keywords: models
> 
> ### ** Examples
> 
> ## Not run: 
> ##D #################################################################
> ##D ## Example 1
> ##D #################################################################
> ##D 
> ##D mydat <- ex0.dag.data[,c("b1","b2","g1","g2","b3","g3")] ## take a subset of cols
> ##D 
> ##D ## setup distribution list for each node
> ##D mydists <- list(b1="binomial", b2="binomial", g1="gaussian",
> ##D               g2="gaussian", b3="binomial", g3="gaussian")
> ##D 
> ##D # Structural constraints
> ##D # ban arc from b2 to b1 
> ##D # always retain arc from g2 to g1
> ##D 
> ##D ## parent limits
> ##D max.par <- list("b1"=2, "b2"=2, "g1"=2, "g2"=2, "b3"=2, "g3"=2)
> ##D 
> ##D ## now build the cache of pre-computed scores accordingly to the structural constraints
> ##D 
> ##D res.c <- buildScoreCache(data.df=mydat, data.dists=mydists,
> ##D               dag.banned= ~b1|b2, dag.retained= ~g1|g2, max.parents=max.par)
> ##D 
> ##D 
> ##D ## repeat but using R-INLA. The mlik's should be virtually identical.
> ##D ## now build cache
> ##D res.inla <- buildScoreCache(data.df=mydat, data.dists=mydists,
> ##D               dag.banned= ~b1|b2, dag.retained= ~g1|g2, max.parents=max.par,
> ##D               max.mode.error=100)
> ##D 
> ##D ## plot comparison - very similar
> ##D plot(res.c$mlik, res.inla$mlik, pch="+") 
> ##D abline(0, 1)
> ##D 
> ##D 
> ##D #################################################################
> ##D ## Example 2 - grouped data - random effects example e.g. glmm
> ##D ###################################################################
> ##D 
> ##D mydat <- ex3.dag.data ## this data comes with abn see ?ex3.dag.data
> ##D 
> ##D mydists <- list(b1="binomial", b2="binomial", b3="binomial",
> ##D             b4="binomial", b5="binomial", b6="binomial", b7="binomial",
> ##D             b8="binomial", b9="binomial", b10="binomial",b11="binomial",
> ##D             b12="binomial", b13="binomial" )
> ##D max.par <- 2
> ##D 
> ##D ## in this example INLA is used as default since these are glmm nodes
> ##D ## when running this at node-parent combination 71 the default accuracy check on the 
> ##D ## INLA modes is exceeded (default is a max. of 10 percent difference from
> ##D ## modes estimated using internal code) and a message is given that internal code
> ##D ## will be used in place of INLA's results.
> ##D 
> ##D # mycache <- buildScoreCache(data.df=mydat, data.dists=mydists, group.var="group",
> ##D #                         cor.vars=c("b1","b2","b3","b4","b5","b6","b7",
> ##D #                                    "b8","b9","b10","b11","b12","b13"),
> ##D #                         max.parents=max.par, which.nodes=c(1))
> ## End(Not run)
> mydat <- ex0.dag.data[,c("b1","b2","g1","g2","b3","g3")] ## take a subset of cols
> 
> ## setup distribution list for each node
> mydists <- list(b1="binomial", b2="binomial", g1="gaussian",
+               g2="gaussian", b3="binomial", g3="gaussian")
>              
> ## now build cache of scores (goodness of fits for each node)
> res.mle <- buildScoreCache(data.df=mydat, data.dists=mydists,
+                            max.parents=3, method="mle")
> res.abn <- buildScoreCache(data.df=mydat, data.dists=mydists,
+                            max.parents=3, method="Bayes")
> 
> #plot(-res.mle$bic, res.abn$mlik)
> 
> 
> 
> cleanEx()
> nameEx("compareDag")
> ### * compareDag
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: compareDag
> ### Title: Compare two DAGs
> ### Aliases: compareDag
> ### Keywords: utilities
> 
> ### ** Examples
> 
> test.m <- matrix(data = c(0,1,0,
+                           0,0,0,
+                           1,0,0), nrow = 3, ncol = 3)
>     
> ref.m <- matrix(data = c(0,0,0,
+                           1,0,0,
+                           1,0,0), nrow = 3, ncol = 3)
>                           
> colnames(test.m) <- rownames(test.m) <- colnames(ref.m) <- colnames(ref.m) <- c("a", "b", "c")
>                           
> compareDag(ref = ref.m, test = test.m)
$TPR
[1] 0.5

$FPR
[1] 0.1428571

$Accuracy
[1] 0.7777778

$FDR
[1] 0.5

$`G-measure`
[1] 0.5

$`F1-score`
[1] 2

$PPV
[1] 0.5

$FOR
[1] 0.5

$`Hamming-distance`
[1] 1

> 
> 
> 
> cleanEx()
> nameEx("createDag")
> ### * createDag
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: createDag
> ### Title: Create a legitimate DAGs
> ### Aliases: createDag createAbnDag
> ### Keywords: utilities
> 
> ### ** Examples
> 
> createAbnDag( ~a+b|a, data.df=c("a"=1, "b"=1))
  a b
a 0 0
b 1 0
Class 'abnDag'.
> 
> plot( createAbnDag( matrix( c(0,1,0,0),2,2))) 
> 
> 
> 
> cleanEx()
> nameEx("dag_ex0")
> ### * dag_ex0
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: ex0.dag.data
> ### Title: Synthetic validation data set for use with abn library examples
> ### Aliases: ex0.dag.data
> ### Keywords: datasets
> 
> ### ** Examples
> 
> ## Not run: 
> ##D ## The dataset was (essentially) generated using the following code:
> ##D datasize <- 300   
> ##D tmp <- c(rep("y", as.integer(datasize/2)), rep("n", as.integer(datasize/2)))
> ##D set.seed(1)
> ##D 
> ##D ex0.dag.data <- data.frame(b1=sample(tmp, size=datasize, replace=TRUE),
> ##D                 b2=sample(tmp, size=datasize, replace=TRUE),
> ##D                 b3=sample(tmp, size=datasize, replace=TRUE),
> ##D                 b4=sample(tmp, size=datasize, replace=TRUE),
> ##D                 b5=sample(tmp, size=datasize, replace=TRUE),
> ##D                 b6=sample(tmp, size=datasize, replace=TRUE),
> ##D                 b7=sample(tmp, size=datasize, replace=TRUE),
> ##D                 b8=sample(tmp, size=datasize, replace=TRUE),
> ##D                 b9=sample(tmp, size=datasize, replace=TRUE),
> ##D                 b10=sample(tmp, size=datasize, replace=TRUE),
> ##D                 g1=rnorm(datasize, mean=0,sd=1),
> ##D                 g2=rnorm(datasize, mean=0,sd=1),
> ##D                 g3=rnorm(datasize, mean=0,sd=1),
> ##D                 g4=rnorm(datasize, mean=0,sd=1),
> ##D                 g5=rnorm(datasize, mean=0,sd=1),
> ##D                 g6=rnorm(datasize, mean=0,sd=1),
> ##D                 g7=rnorm(datasize, mean=0,sd=1),
> ##D                 g8=rnorm(datasize, mean=0,sd=1),
> ##D                 g9=rnorm(datasize, mean=0,sd=1),
> ##D                 g10=rnorm(datasize, mean=0,sd=1),
> ##D                 p1=rpois(datasize, lambda=10),
> ##D                 p2=rpois(datasize, lambda=10),
> ##D                 p3=rpois(datasize, lambda=10),
> ##D                 p4=rpois(datasize, lambda=10),
> ##D                 p5=rpois(datasize, lambda=10),
> ##D                 p6=rpois(datasize, lambda=10),
> ##D                 p7=rpois(datasize, lambda=10),
> ##D                 p8=rpois(datasize, lambda=10),
> ##D                 p9=rpois(datasize, lambda=10),
> ##D                 p10=rpois(datasize, lambda=10))
> ## End(Not run)
> 
> 
> 
> cleanEx()
> nameEx("dag_ex1")
> ### * dag_ex1
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: ex1.dag.data
> ### Title: Synthetic validation data set for use with abn library examples
> ### Aliases: ex1.dag.data
> ### Keywords: datasets
> 
> ### ** Examples
> 
> ## The data is one realisation from the the underlying DAG:
> ex1.true.dag <- matrix(data=c(
+   0,0,0,0,0,0,0,0,0,0,
+   0,0,0,0,0,0,0,0,0,0,
+   0,0,0,0,0,0,0,0,0,0,
+   0,0,0,0,0,0,0,0,0,0,
+   1,1,0,0,0,0,0,0,0,0,
+   1,0,1,1,0,0,0,0,0,0,
+   0,1,1,1,0,0,0,0,0,0,
+   0,0,1,0,1,0,0,0,0,0,
+   0,0,1,0,0,0,1,0,0,0,
+   0,0,1,1,0,0,0,0,0,0), ncol=10, byrow=TRUE)
> 
> colnames(ex1.true.dag) <- rownames(ex1.true.dag) <-
+     c("b1","p1","g1","b2","p2","b3","g2","b4","b5","g3")
> 
> 
> 
> cleanEx()
> nameEx("dag_ex2")
> ### * dag_ex2
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: ex2.dag.data
> ### Title: Synthetic validation data set for use with abn library examples
> ### Aliases: ex2.dag.data
> ### Keywords: datasets
> 
> ### ** Examples
> 
> ## The true underlying stochastic model has DAG - this data is a single realisation.
> ex2.true.dag <- matrix(data = c(
+    0,1,0,1,0,0,1,0,1,1,1,0,1,0,0,0,0,0, 
+    0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
+    0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,
+    0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,1,
+    0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
+    0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
+    0,1,0,0,1,1,0,1,1,0,1,0,0,0,0,0,0,0,
+    0,1,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,
+    0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
+    0,1,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,
+    0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,
+    0,1,0,1,1,0,0,0,0,0,0,0,1,0,0,0,0,0,
+    0,0,0,1,1,0,1,0,1,0,1,0,0,0,0,0,0,0,
+    0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
+    0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,1,1,0,
+    0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
+    0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
+    0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
+    ), ncol = 18, byrow = TRUE)
> 
> colnames(ex2.true.dag) <- rownames(ex2.true.dag) <- c("b1","g1","p1","b2",
+   "g2","p2","b3","g3","p3","b4","g4","p4","b5","g5","p5","b6","g6","p6")
> 
> 
> 
> cleanEx()
> nameEx("discretization")
> ### * discretization
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: discretization
> ### Title: Discretization of a Possibly Continuous Data Frame of Random
> ###   Variables based on their distribution
> ### Aliases: discretization
> ### Keywords: utilities
> 
> ### ** Examples
> 
> ## Generate random variable
> rv <- rnorm(n = 100, mean = 5, sd = 2)
> dist <- list("gaussian")
> names(dist) <- c("rv")
> 
> ## Compute the entropy through discretization
> entropyData(freqs.table = discretization(data.df = rv, data.dists = dist,
+             discretization.method = "sturges", nb.states = FALSE))
[1] 2.654889
> 
> 
> 
> cleanEx()
> nameEx("entropyData")
> ### * entropyData
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: entropyData
> ### Title: Computes an Empirical Estimation of the Entropy from a Table of
> ###   Counts
> ### Aliases: entropyData
> ### Keywords: utilities
> 
> ### ** Examples
> 
> ## Generate random variable
> rv <- rnorm(n = 100, mean = 0, sd = 2)
> dist <- list("gaussian")
> names(dist) <- c("rv")
> 
> ## Compute the entropy through discretization
> entropyData(discretization(data.df = rv, data.dists = dist,
+                         discretization.method = "fd", nb.states = FALSE))
[1] 0
> 
> 
> 
> cleanEx()
> nameEx("essentialGraph")
> ### * essentialGraph
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: essentialGraph
> ### Title: Construct the essential graph
> ### Aliases: essentialGraph
> ### Keywords: utilities
> 
> ### ** Examples
> 
> dag <- matrix(c(0,0,0, 1,0,0, 1,1,0), nrow = 3, ncol = 3)
> dist <- list(a="gaussian", b="gaussian", c="gaussian")
> colnames(dag) <- rownames(dag) <- names(dist)
> 
> essentialGraph(dag)
  a b c
a 0 1 1
b 0 0 1
c 0 1 0
> 
> 
> 
> cleanEx()
> nameEx("fitabn")
> ### * fitabn
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: fitabn
> ### Title: Fit an additive Bayesian network model
> ### Aliases: fitAbn
> ### Keywords: models
> 
> ### ** Examples
> 
> 
> ## Built-in dataset with a subset of cols  
> mydat <- ex0.dag.data[,c("b1","b2","b3","g1","b4","p2","p4")] 
> 
> 
> ## setup distribution list for each node
> mydists <- list(b1="binomial", b2="binomial", b3="binomial", g1="gaussian",
+               b4="binomial", p2="poisson", p4="poisson")
> 
> ## Null model - all independent variables
> mydag.empty <- matrix(0, nrow=7, ncol=7)
> colnames(mydag.empty) <- rownames(mydag.empty) <- names(mydat)
> 
> ## Now fit the model to calculate its goodness-of-fit
> myres <- fitAbn(dag=mydag.empty, data.df=mydat, data.dists=mydists)
> 
> ## Log-marginal likelihood goodness-of-fit for complete DAG
> print(myres$mlik) 
[1] -2855.45
> 
> ## Not run: 
> ##D ## Now repeat but include some dependencies first
> ##D mydag <- mydag.empty 
> ##D mydag["b1","b2"] <- 1 # b1<-b2 
> ##D mydag["b2","p4"] <- 1 # b2<-p4
> ##D mydag["b2","g1"] <- 1 # b2<-g1
> ##D mydag["g1","p2"] <- 1 # g1<-p2
> ##D mydag["b3","g1"] <- 1 # b3<-g1
> ##D mydag["b4","b1"] <- 1 # b4<-b1
> ##D mydag["p4","g1"] <- 1 # p4<-g1
> ##D 
> ##D # fit  using the formula statement 
> ##D #  including the creation of the graph of the DAG via Rgraphviz 
> ##D myres <- fitAbn(dag=~b1|b2+b2|p4+g1+g1|p2+b3|g1+b4|b1+p4|g1,
> ##D                 data.df=mydat, data.dists=mydists,
> ##D                 create.graph=TRUE)
> ##D 
> ##D ## Or equivalentelly using the formula statement
> ##D # myres <- fitAbn(dag=mydag, data.df=mydat, data.dists=mydists,
> ##D #              create.graph=TRUE)
> ##D 
> ##D print(myres$mlik) ## a much weaker fit than full independence DAG
> ##D 
> ##D plotAbn(dag=mydag, data.dists=mydists, fitted.values.abn=myres$modes)
> ##D 
> ##D ## A simple plot of some posterior densities the algorithm which chooses 
> ##D ## density points is very simple any may be rather sparse so also recompute 
> ##D ## the density over an equally spaced grid of 50 points between the two 
> ##D ## end points which had at f=min.pdf
> ##D ## max.mode.error=0 foces to use the internal c code
> ##D myres.c <- fitAbn(dag=mydag, data.df=mydat, data.dists=mydists, 
> ##D                   compute.fixed=TRUE, n.grid=50, max.mode.error=0)
> ##D 
> ##D print(names(myres.c$marginals)) ## gives all the different parameter names
> ##D 
> ##D ## Repeat but use INLA for the numerics using max.mode.error=100
> ##D ## as using internal code is the default here rather than INLA 
> ##D myres.inla <- fitAbn(dag=mydag, data.df=mydat, data.dists=mydists,
> ##D                      compute.fixed=TRUE, n.grid=50, max.mode.error=100)
> ##D 
> ##D ## Plot posterior densities
> ##D par(mfrow=c(2,2), mai=c(.7,.7,.2,.1))
> ##D plot(myres.c$marginals$b1[["b1|(Intercept)"]], type="l", xlab="b1|(Intercept)")
> ##D lines(myres.inla$marginals$b1[["b1|(Intercept)"]], col="blue")
> ##D plot(myres.c$marginals$b2[["b2|p4"]], type="l", xlab="b2|p4")
> ##D lines(myres.inla$marginals$b2[["b2|p4"]], col="blue")
> ##D plot(myres.c$marginals$g1[["g1|precision"]], type="l", xlab="g1|precision")
> ##D lines(myres.inla$marginals$g1[["g1|precision"]], col="blue")
> ##D plot(myres.c$marginals$b4[["b4|b1"]], type="l", xlab="b4|b1")
> ##D lines(myres.inla$marginals$b4[["b4|b1"]], col="blue")
> ##D 
> ##D ## An elementary mixed model example using built-in data specify DAG, 
> ##D ## only two variables using a subset of variables from ex3.dag.data
> ##D ## both variables are assumed to need (separate) adjustment for the 
> ##D ## group variable, i.e., a binomial GLMM at each node
> ##D 
> ##D 
> ##D mydists <- list(b1="binomial",  b2="binomial")
> ##D 
> ##D ## Compute marginal likelihood - use internal code via max.mode.error=0
> ##D ## as using INLA is the default here.
> ##D ## Model where b1 <- b2
> ##D myres.c <- fitAbn(dag=~b1|b2, data.df=ex3.dag.data[,c(1,2,14)], data.dists=mydists,
> ##D                   group.var="group", cor.vars=c("b1","b2"),
> ##D                   max.mode.error=0)
> ##D print(myres.c) ## show all the output 
> ##D 
> ##D ## compare mode for node b1 with glmer(), lme4::glmer is automatically attached.
> ##D m1 <- glmer(b1 ~ 1 + b2 + (1|group), 
> ##D             family="binomial", data=ex3.dag.data[,c(1,2,14)])
> ##D 
> ##D print(myres.c$modes$b1) ## almost identical to lme4 n.b. glmer() gives variance
> ##D ##                         fitAbn gives precision=1/variance
> ##D 
> ##D ## Compare with INLA estimate
> ##D myres.inla <- fitAbn(dag=~b1|b2,data.df=ex3.dag.data[,c(1,2,14)],
> ##D                      data.dists=mydists, group.var="group", cor.vars=c("b1","b2"),
> ##D                      compute.fixed=FALSE, max.mode.error=100)
> ##D 
> ##D ## Compare log marginal likelihoods for each node and total DAG:
> ##D cbind(INLA=unlist(myres.inla[1:3]), C=unlist(myres.c[1:3]), 
> ##D              Delta=unlist(myres.inla[1:3]) - unlist(myres.c[1:3]))
> ##D 
> ##D ## Now for marginals - INLA is strongly preferable for estimating marginals for nodes 
> ##D ## with random effects as it is far faster, but may not be reliable
> ##D ## see http://r-bayesian-networks.org
> ##D 
> ##D ## INLA's estimates of the marginals, using high n.grid=500
> ##D ## as this makes the plots smoother - see below.
> ##D ## myres.inla <- fitAbn(dag=~b1|b2, data.df=ex3.dag.data[,c(1,2,14)], 
> ##D #                      data.dists=mydists,
> ##D #                      group.var="group", cor.vars=c("b1", "b2"),
> ##D #                      compute.fixed=TRUE, n.grid=500, 
> ##D #                      control=list(max.mode.error=100, max.hessian.error=10E-02))
> ##D 
> ##D ## this is NOT recommended - marginal density estimation using fitAbn in mixed models
> ##D ## is really just for diagnostic purposes, better to use fitAbn.inla() here
> ##D ## but here goes...be patient
> ##D # myres.c <- fitAbn(dag=~b1|b2, data.df=ex3.dag.data[,c(1,2,14)], data.dists=mydists,
> ##D #                   group.var="group", cor.vars=c("b1", "b2"), compute.fixed=TRUE,
> ##D #                   control=list(max.mode.error=0, max.hessian.error=10E-02))
> ##D 
> ##D ## compare marginals between internal and INLA.   
> ##D # par(mfrow=c(2,3))
> ##D ## 5 parameters - two intercepts, one slope, two group level precisions
> ##D # plot(myres.inla$marginals$b1[[1]], type="l", col="blue")
> ##D # lines(myres.c$marginals$b1[[1]], col="brown", lwd=2)
> ##D # plot(myres.inla$marginals$b1[[2]], type="l", col="blue")
> ##D # lines(myres.c$marginals$b1[[2]], col="brown", lwd=2)
> ##D ## the precision of group-level random effects
> ##D # plot(myres.inla$marginals$b1[[3]],type="l", col="blue", xlim=c(0,2))
> ##D # lines(myres.c$marginals$b1[[3]],col="brown",lwd=2)
> ##D # plot(myres.inla$marginals$b2[[1]],type="l", col="blue")
> ##D # lines(myres.c$marginals$b2[[1]],col="brown",lwd=2)
> ##D # plot(myres.inla$marginals$b2[[1]], type="l", col="blue")
> ##D # lines(myres.c$marginals$b2[[1]], col="brown", lwd=2)
> ##D ## the precision of group-level random effects
> ##D # plot(myres.inla$marginals$b2[[2]], type="l", col="blue", xlim=c(0,2))
> ##D # lines(myres.c$marginals$b2[[2]], col="brown", lwd=2)
> ##D 
> ##D ### these are very similar although not exactly identical
> ##D 
> ##D ## use internal code but only to compute a single parameter over a specified grid
> ##D ## This can be necessary if the simple auto grid finding functions does a poor job
> ##D 
> ##D #myres.c <- fitAbn(dag=~b1|b2, data.df=ex3.dag.data[,c(1,2,14)], data.dists=mydists,
> ##D #                  group.var="group", cor.vars=c("b1", "b2"), 
> ##D #                  centre=FALSE, compute.fixed=TRUE,
> ##D #                  marginal.node=1, marginal.param=3,## precision term in node 1
> ##D #                  variate.vec=seq(0.05, 1.5, len=25), max.hessian.error=10E-02)
> ##D 
> ##D #par(mfrow=c(1,2))
> ##D #plot(myres.c$marginals[[1]], type="l", col="blue")## still fairly sparse
> ##D ## An easy way is to use spline to fill in the density without recomputing other
> ##D ## points provided the original grid is not too sparse.
> ##D #plot(spline(myres.c$marginals[[1]], n=100), type="b", col="brown")
> ##D 
> ##D ## -----------------------------------------------------------------------------------
> ##D ## This function contains an MLE implementation accessible through a method parameter
> ##D ## use built-in simulated data set
> ##D ## -----------------------------------------------------------------------------------
> ##D 
> ##D mydat <- ex0.dag.data[,c("b1","b2","b3","g1","b4","p2","p4")] ## take a subset of cols
> ##D 
> ##D ## setup distribution list for each node
> ##D mydists <- list(b1="binomial", b2="binomial", b3="binomial",
> ##D                 g1="gaussian", b4="binomial", p2="poisson", p4="poisson")
> ##D 
> ##D 
> ##D ## now fit the model to calculate its goodness of fit
> ##D myres.mle <- fitAbn(dag=~b1|b2+b2|p4+g1+g1|p2+b3|g1+b4|b1+p4|g1, 
> ##D                     data.df=mydat, data.dists=mydists, method="mle")
> ##D 
> ##D myres.bayes <- fitAbn(dag=~b1|b2+b2|p4+g1+g1|p2+b3|g1+b4|b1+p4|g1, 
> ##D                       data.df=mydat, data.dists=mydists, method="bayes")
> ##D 
> ##D ## print the output
> ##D ## MLE
> ##D print(myres.mle)
> ##D 
> ##D #Bayes
> ##D print(myres.bayes)
> ##D 
> ##D ## plot the model with parameter estimates
> ##D plotAbn(dag=mydag, data.dists=mydists, fitted.values.abn.mle=myres.bayes$modes)
> ## End(Not run)
> 
> 
> 
> 
> cleanEx()
> nameEx("infoDag")
> ### * infoDag
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: infoDag
> ### Title: Compute standard information for a DAG.
> ### Aliases: infoDag
> ### Keywords: utilities
> 
> ### ** Examples
> 
> ## Creating a dag:
> dag <- matrix(c(0,0,0,0, 1,0,0,0, 1,1,0,1, 0,1,0,0), nrow = 4, ncol = 4)
> dist <- list(a="gaussian", b="gaussian", c="gaussian", d="gaussian")
> colnames(dag) <- rownames(dag) <- names(dist)
>     
> infoDag(dag)
$n.nodes
[1] 4

$n.arcs
[1] 5

$mb.average
[1] 3

$nh.average
[1] 2.5

$parent.average
[1] 1.25

$children.average
[1] 1.25

> plot(createAbnDag(dag))
dev.new(): using pdf(file="Rplots1.pdf")
> 
> 
> 
> 
> cleanEx()
> nameEx("link_strength")
> ### * link_strength
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: linkStrength
> ### Title: A function that returns the strengths of the edge connections in
> ###   a Bayesian Network learned from observational data.
> ### Aliases: linkStrength link.strength linkstrength
> ### Keywords: utilities
> 
> ### ** Examples
> 
> 
> dist <- list(a="gaussian", b="gaussian", c="gaussian")
> data.param <- matrix(c(0,1,0, 0,0,1, 0,0,0), nrow = 3L, ncol = 3L, byrow = TRUE)
>     
> data.param.var <- matrix(0, nrow = 3L, ncol = 3L)
> diag(data.param.var) <- c(0.1,0.1,0.1)
>     
> out <- simulateAbn(data.dists = dist,
+     n.chains = 1, n.adapt = 1000, n.thin = 1, n.iter = 100,
+     data.param = data.param, data.param.var = data.param.var)
Creation of the BUG file: model.bug
BUG file created
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 0
   Unobserved stochastic nodes: 3
   Total graph size: 10

Initializing model

> 
> linkStrength(data.param, data.df = out, data.dists = dist,
+              method = "ls", discretization.method = "sturges")
     [,1]     [,2]     [,3]
[1,]    0 5.166889 0.000000
[2,]    0 0.000000 5.167048
[3,]    0 0.000000 0.000000
> 
> 
> 
> 
> cleanEx()
> nameEx("mb")
> ### * mb
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: mb
> ### Title: Compute the Markov blanket
> ### Aliases: mb
> ### Keywords: utilities
> 
> ### ** Examples
> 
> ## Defining distribution and dag
> dist <- list(a="gaussian", b="gaussian", c="gaussian", d="gaussian",
+              e="binomial", f="binomial")
> dag <- matrix(c(0,1,1,0,1,0,
+     0,0,1,1,0,1, 
+     0,0,0,0,0,0, 
+     0,0,0,0,0,0, 
+     0,0,0,0,0,1, 
+     0,0,0,0,0,0), nrow = 6L, ncol = 6L, byrow = TRUE)    
> colnames(dag) <- rownames(dag) <- names(dist)
>     
> mb(dag, node = "b")
[1] "a" "c" "d" "f" "e"
> mb(dag, node = c("b","e"))
[1] "a" "c" "d" "f" "e" "b"
> 
> mb(~a|b:c:e+b|c:d:f+e|f, node = "e", data.dists = dist)
[1] "a" "f" "b" "c"
> 
> 
> 
> cleanEx()
> nameEx("miData")
> ### * miData
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: miData
> ### Title: Empirical Estimation of the Entropy from a Table of Counts
> ### Aliases: miData
> ### Keywords: utilities
> 
> ### ** Examples
> 
> ## Generate random variable
> Y <- rnorm(n = 100, mean = 0, sd = 2)
> X <- rnorm(n = 100, mean = 5, sd = 2)
> 
> dist <- list(Y="gaussian", X="gaussian")
> 
> miData(discretization(data.df = cbind(X,Y), data.dists = dist,
+                 discretization.method = "fd", nb.states = FALSE),
+        method = "mi.raw")
[1] 0
> 
> 
> 
> cleanEx()
> nameEx("mostprobable")
> ### * mostprobable
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: mostprobable
> ### Title: Find most probable DAG structure
> ### Aliases: mostProbable
> ### Keywords: models
> 
> ### ** Examples
> 
> ## Not run: 
> ##D ##############################
> ##D ## Example 1
> ##D ##############################
> ##D 
> ##D ## this data comes with abn see ?ex1.dag.data
> ##D mydat <- ex1.dag.data
> ##D 
> ##D ## setup distribution list for each node
> ##D mydists <- list(b1="binomial", p1="poisson", g1="gaussian", b2="binomial",
> ##D               p2="poisson", b3="binomial", g2="gaussian", b4="binomial",
> ##D               b5="binomial", g3="gaussian")
> ##D 
> ##D ## assum no constraints in ban nor retain
> ##D 
> ##D ## parent limits
> ##D max.par <- list("b1"=0,"p1"=0,"g1"=1,"b2"=1,"p2"=2,"b3"=3,"g2"=3,"b4"=2,"b5"=2,"g3"=2)
> ##D ## now build cache
> ##D mycache <- buildScoreCache(data.df=mydat, data.dists=mydists, max.parents=max.par)
> ##D 
> ##D ## Find the globally best DAG
> ##D mp.dag <- mostProbable(score.cache=mycache)
> ##D fitAbn(object=mp.dag)$mlik
> ##D 
> ##D ## plot the best model
> ##D myres <- fitAbn(object=mp.dag,create.graph=TRUE)
> ##D 
> ##D plotAbn(dag=mp.dag$dag, data.dists=mydists)#, fitted.values.abn=myres)
> ##D 
> ##D ## fit the known true DAG
> ##D true.dag <- matrix(data=0,ncol=10, nrow=10)
> ##D colnames(true.dag) <- rownames(true.dag) <- names(mydists)
> ##D 
> ##D true.dag["p2",c("b1","p1")] <- 1
> ##D true.dag["b3",c("b1","g1","b2")] <- 1
> ##D true.dag["g2",c("p1","g1","b2")] <- 1
> ##D true.dag["b4",c("g1","p2")] <- 1
> ##D true.dag["b5",c("g1","g2")] <- 1
> ##D true.dag["g3",c("g1","b2")] <- 1
> ##D 
> ##D fitAbn(dag=true.dag, data.df=mydat, data.dists=mydists)$mlik
> ##D 
> ##D #################################################################
> ##D ## Example 2 - models with random effects
> ##D #################################################################
> ##D 
> ##D ## this data comes with abn see ?ex3.dag.data
> ##D # mydat <- ex3.dag.data[,c(1:4,14)]
> ##D 
> ##D # mydists <- list(b1="binomial", b2="binomial", b3="binomial",
> ##D #              b4="binomial")
> ##D 
> ##D ## This takes a few seconds
> ##D # mycache.mixed <- buildScoreCache(data.df=mydat, data.dists=mydists,
> ##D #               group.var="group", cor.vars=c("b1","b2","b3","b4"),
> ##D #               max.parents=2, which.nodes=c(1:4))
> ##D 
> ##D ## find the most probable DAG
> ##D # mp.dag <- mostProbable(score.cache=mycache.mixed)
> ##D 
> ##D ## get goodness of fit
> ##D # fitAbn(object=mp.dag, data.df=mydat, data.dists=mydists,
> ##D #      group.var="group", cor.vars=c("b1","b2","b3","b4"))$mlik
> ## End(Not run)
> 
> 
> cleanEx()
> nameEx("plot-abn")
> ### * plot-abn
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: plotabn
> ### Title: Plot an ABN graphic
> ### Aliases: plotAbn
> ### Keywords: models hplot
> 
> ### ** Examples
> 
> #Define distribution list
> dist <- list(a="gaussian", b="gaussian", c="gaussian", d="gaussian", e="binomial", f="binomial")
> 
> #Define a matrix formulation
> arc.strength <- matrix(c(0,0.5,0.5,0.7,0.1,0,
+                               0,0,0.3,0.1,0,0.8,
+                               0,0,0,0.35,0.66,0,
+                               0,0,0,0,0.9,0,
+                               0,0,0,0,0,0.8,
+                               0,0,0,0,0,0),nrow = 6L, ncol = 6L, byrow = TRUE)
> 
> #Naming of the matrix
> colnames(arc.strength) <- rownames(arc.strength) <- names(dist)
> 
> #Plot from a formula
> plotAbn(dag = ~a|b:c:e+b|c:d:f+e|f, data.dist = dist)
> 
> #Plot form a matrix
> plotAbn(dag = arc.strength, data.dist = dist)
> 
> #Arc strength
> plotAbn(dag = ~a|b:c:e+b|c:d:f+e|f, data.dist = dist, arc.strength = arc.strength)
Warning in plot.window(xlim = c(getX(bl), getX(ur)), ylim = c(getY(bl),  :
  "arc.strength" is not a graphical parameter
> 
> #Markov blanket
> plotAbn(dag = ~a|b:c:e+b|c:d:f+e|f, data.dists = dist, markov.blanket.node = "e")
> 
> 
> 
> cleanEx()
> nameEx("scoreContribution")
> ### * scoreContribution
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: scoreContribution
> ### Title: Compute the score's contribution in a network of each
> ###   observation.
> ### Aliases: scoreContribution
> ### Keywords: utilities
> 
> ### ** Examples
> 
> 
> ## Use a subset of a built-in simulated data set
> mydat <- ex1.dag.data[,c("b1","g1","p1")]
> 
> ## setup distribution list for each node
> mydists <- list(b1="binomial", g1="gaussian", p1="poisson")
> 
> ## now build cache
> mycache <- buildScoreCache(data.df = mydat, data.dists = mydists, max.parents = 2, method = "mle")
> 
> ## Find the globally best DAG
> mp.dag <- mostProbable(score.cache=mycache, score="bic", verbose = FALSE)
> 
> out <- scoreContribution(object = mp.dag)
> 
> ## Observations contribution per network node
> boxplot(out$bic)
> 
> 
> 
> 
> cleanEx()
> nameEx("search_heuristic")
> ### * search_heuristic
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: searchHeuristic
> ### Title: A family of heuristic algorithms that aims at finding high
> ###   scoring directed acyclic graphs
> ### Aliases: search.heuristic searchHeuristic
> ### Keywords: models
> 
> ### ** Examples
> 
> ## Not run: 
> ##D 
> ##D ##############################################
> ##D ## example: use built-in simulated data set
> ##D ##############################################
> ##D 
> ##D mydat <- ex1.dag.data ## this data comes with abn see ?ex1.dag.data
> ##D 
> ##D ## setup distribution list for each node
> ##D mydists<-list(b1="binomial", p1="poisson", g1="gaussian", b2="binomial",
> ##D               p2="poisson", b3="binomial", g2="gaussian", b4="binomial",
> ##D               b5="binomial", g3="gaussian")
> ##D 
> ##D mycache <- buildScoreCache(data.df = mydat, data.dists = mydists, max.parents = 2)
> ##D 
> ##D ## Now peform 10 greedy searches
> ##D heur.res <- searchHeuristic(score.cache = mycache, data.dists = mydists,
> ##D               start.dag = "random", num.searches = 10,
> ##D               max.steps = 50)
> ##D 
> ##D ## Plot (one) dag
> ##D plotAbn(heur.res$dags[[1]], data.dists = mydists)
> ## End(Not run)
> 
> 
> cleanEx()
> nameEx("search_hillclimber")
> ### * search_hillclimber
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: searchHillclimber
> ### Title: Find high scoring directed acyclic graphs using heuristic
> ###   search.
> ### Aliases: searchHillClimber
> ### Keywords: models
> 
> ### ** Examples
> 
> ## Not run: 
> ##D ##############################################
> ##D ## example 1: use built-in simulated data set
> ##D ##############################################
> ##D 
> ##D ## this data comes with abn see ?ex1.dag.data
> ##D mydat <- ex1.dag.data
> ##D 
> ##D ## setup distribution list for each node
> ##D mydists <- list(b1="binomial", p1="poisson", g1="gaussian", b2="binomial",
> ##D               p2="poisson", b3="binomial", g2="gaussian", b4="binomial",
> ##D               b5="binomial", g3="gaussian")
> ##D 
> ##D ## Build cache may take some minutes for buildScoreCache()
> ##D mycache <- buildScoreCache(data.df=mydat, data.dists=mydists,
> ##D                            max.parents=2);
> ##D 
> ##D # now peform 10 greedy searches
> ##D heur.res <- searchHillClimber(score.cache=mycache,
> ##D                  num.searches=10, timing.on=FALSE)
> ##D plotAbn(dag=heur.res$consensus, data.dists=mydists)
> ##D 
> ##D ###########################
> ##D ## example 2 - glmm example
> ##D ###########################
> ##D 
> ##D ## this data comes with abn see ?ex1.dag.data
> ##D mydat <- ex3.dag.data[,c(1:4,14)]
> ##D 
> ##D mydists <- list(b1="binomial", b2="binomial", b3="binomial",
> ##D               b4="binomial")
> ##D 
> ##D ## This takes a few seconds
> ##D # mycache.mixed <- buildScoreCache(data.df=mydat, data.dists=mydists,
> ##D #               group.var="group", cor.vars=c("b1","b2","b3","b4"),
> ##D #               max.parents=2, which.nodes=c(1:4))
> ##D 
> ##D ## Now peform 50 greedy searches
> ##D # heur.res <- searchHillClimber(score.cache=mycache.mixed, num.searches=50,
> ##D #                              timing.on=FALSE)
> ##D ##  Plot the majority consensus network
> ##D # plotAbn(dag=heur.res$consensus, data.dists=mydists)
> ##D 
> ## End(Not run)
> 
> 
> cleanEx()
> nameEx("simulate-abn")
> ### * simulate-abn
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: simulateAbn
> ### Title: Simulate from an ABN Network
> ### Aliases: simulateAbn simulate.abn simulateabn
> ### Keywords: utilities
> 
> ### ** Examples
> 
> ## Define set of distributions:
> dist<-list(a="gaussian", b="gaussian", c="gaussian", d="gaussian", 
+            e="binomial", f="binomial")
> 
> ## Define parameter matrix:
> data.param <- matrix(c(1,2,0.5,0,20,0,
+                        0,1,3,10,0, 0.8,
+                        0,0,1,0,0,0,
+                        0,0,0,1,0,0,
+                        0,0,0,0,0.5,1,
+                        0,0,0,0,0,0), nrow = 6L, ncol = 6L, byrow = TRUE)
> 
> ## Define precision matrix: 
> data.param.var <- matrix(0, nrow = 6L, ncol = 6L)
> diag(data.param.var) <- c(10,20,30,40,0,0)
> 
> ## Plot the dag
> plotAbn(dag = ~a|b:c:e+b|c:d:f+e|f, data.dists = dist)
> 
> ## Simulate the data
> out <- simulateAbn(data.dists=dist, n.chains=1, n.thin=1, n.iter=1000,
+             data.param=data.param, data.param.var=data.param.var)
Creation of the BUG file: model.bug
BUG file created
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 0
   Unobserved stochastic nodes: 6
   Total graph size: 28

Initializing model

> 
> 
> 
> cleanEx()
> nameEx("simulate-dag")
> ### * simulate-dag
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: simulateDag
> ### Title: Simulate DAGs
> ### Aliases: simulateDag simulate.dag
> ### Keywords: utilities
> 
> ### ** Examples
> 
> ## Example using Ozon entries:
> dist <- list(Ozone="gaussian",   Solar.R="gaussian",  Wind="gaussian", 
+              Temp="gaussian",    Month="gaussian",    Day="gaussian")
> out <- simulateDag(node.name = names(dist), data.dists = dist, edge.density = 0.8)
> plot(out)
dev.new(): using pdf(file="Rplots2.pdf")
> 
> 
> 
> 
> cleanEx()
> nameEx("tographviz")
> ### * tographviz
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: tographviz
> ### Title: Convert a DAG into graphviz format
> ### Aliases: tographviz toGraphviz
> ### Keywords: device
> 
> ### ** Examples
> 
> ## On a typical linux system the following code constructs a nice
> ## looking pdf file 'graph.pdf'.
> ## Not run: 
> ##D ## Subset of a build-in dataset
> ##D mydat <- ex0.dag.data[,c("b1","b2","b3","g1","b4","p2","p4")]
> ##D 
> ##D ## setup distribution list for each node
> ##D mydists <- list(b1="binomial", b2="binomial", b3="binomial",
> ##D                 g1="gaussian", b4="binomial", p2="poisson",
> ##D                 p4="poisson")
> ##D ## specify DAG model 
> ##D mydag <- matrix(c(   0,1,0,0,1,0,0, # 
> ##D                      0,0,0,0,0,0,0, #
> ##D                      0,1,0,0,1,0,0, # 
> ##D                      1,0,0,0,0,0,1, # 
> ##D                      0,0,0,0,0,0,0, #
> ##D                      0,0,0,1,0,0,0, #
> ##D                      0,0,0,0,1,0,0  #
> ##D                      ), byrow=TRUE, ncol=7)
> ##D                      
> ##D colnames(mydag) <- rownames(mydag) <- names(mydat)
> ##D 
> ##D ## create file for processing with graphviz
> ##D outfile <- paste(tempdir(), "graph.dot", sep="/")
> ##D toGraphviz(dag=mydag, data.df=mydat, data.dists=mydists, outfile=outfile)
> ##D ## and then process using graphviz tools e.g. on linux
> ##D # system(paste( "dot -Tpdf -o graph.pdf", outfile))
> ##D # system("evince graph.pdf")
> ##D 
> ##D ## Example using data with a group variable  where b1<-b2
> ##D mydag <- matrix(c(0,1, 0,0), byrow=TRUE, ncol=2)
> ##D 
> ##D colnames(mydag) <- rownames(mydag) <- names(ex3.dag.data[,c(1,2)])
> ##D ## specific distributions
> ##D mydists <- list(b1="binomial", b2="binomial")
> ##D 
> ##D ## create file for processing with graphviz
> ##D outfile <- paste(tempdir(), "graph.dot", sep="/")
> ##D toGraphviz(dag=mydag, data.df=ex3.dag.data[,c(1,2,14)], data.dists=mydists,
> ##D            group.var="group", 
> ##D            outfile=outfile, directed=FALSE)
> ##D ## and then process using graphviz tools e.g. on linux
> ##D # system(paste( "dot -Tpdf -o graph.pdf", outfile))
> ##D # system("evince graph.pdf")
> ## End(Not run)
> 
> 
> 
> 
> cleanEx()
> nameEx("var33")
> ### * var33
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: var33
> ### Title: simulated dataset from a DAG comprising of 33 variables
> ### Aliases: var33
> ### Keywords: datasets
> 
> ### ** Examples
> 
> ## Constructing the DAG of the dataset:  
> dag33 <- matrix(0, 33, 33)
> dag33[2,1] <- 1
> dag33[4,3] <- 1
> dag33[6,4] <- 1; dag33[6,7] <- 1
> dag33[5,6] <- 1
> dag33[7,8] <- 1  
> dag33[8,9] <- 1
> dag33[9,10] <- 1
> dag33[11,10] <- 1; dag33[11,12] <- 1; dag33[11,19] <- 1;
> dag33[14,13] <- 1
> dag33[17,16] <- 1; dag33[17,20] <- 1
> dag33[15,14] <- 1; dag33[15,21] <- 1
> dag33[18,20] <- 1
> dag33[19,20] <- 1
> dag33[21,20] <- 1
> dag33[22,21] <- 1
> dag33[23,21] <- 1
> dag33[24,23] <- 1
> dag33[25,23] <- 1; dag33[25,26] <- 1
> dag33[26,20] <- 1
> dag33[33,31] <- 1
> dag33[33,31] <- 1
> dag33[32,21] <- 1; dag33[32,31] <- 1; dag33[32,29] <- 1    
> dag33[30,29] <- 1
> dag33[28,27] <- 1; dag33[28,29] <- 1; dag33[28,31] <- 1   
>     
> 
> 
> ### * <FOOTER>
> ###
> cleanEx()
> options(digits = 7L)
> base::cat("Time elapsed: ", proc.time() - base::get("ptime", pos = 'CheckExEnv'),"\n")
Time elapsed:  2.594 0.234 2.536 0 0 
> grDevices::dev.off()
pdf 
  2 
> ###
> ### Local variables: ***
> ### mode: outline-minor ***
> ### outline-regexp: "\\(> \\)?### [*]+" ***
> ### End: ***
> quit('no')
