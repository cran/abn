% -*- mode: noweb; noweb-default-code-mode: R-mode; -*-
\documentclass[nojss]{jss}
%\include{graphicx}
\usepackage[nogin]{Sweave}

\usepackage{multicol} % This is so we can have multiple columns of text side-by-side
\columnsep=100pt % This is the amount of white space between the columns in the poster
\columnseprule=3pt % This is the thickness of the black line between the columns in the poster

\usepackage[svgnames]{xcolor} % Specify colors by their 'svgnames', for a full list of all colors available see here: http://www.latextemplates.com/svgnames-colors

\usepackage{times} % Use the times font
%\usepackage{palatino} % Uncomment to use the Palatino font

% Package Imported from Exo/Make:
\usepackage{natbib}
\usepackage{calc}
\usepackage{url}
%\usepackage[colorlinks=true,pdftex]{hyperref}
\usepackage{bm}
\usepackage{rotate}

%\usepackage{graphics}
%\usepackage{epstopdf}
\usepackage{graphicx} % Required for including images
\graphicspath{{figures/}} % Location of the graphics files
\DeclareGraphicsExtensions{.pdf,.png,.jpg}
\usepackage{booktabs} % Top and bottom rules for table
\usepackage[font=small,labelfont=bf]{caption} % Required for specifying captions to tables and figures
\usepackage{amsfonts, amsmath, amsthm, amssymb} % For math fonts, symbols and environments
\usepackage{wrapfig} % Allows wrapping text around tables and figures

\parindent0pt
%\DefineVerbatimEnvironment{Sinput}{Verbatim}{fontshape=sl,formatcom=\color{DarkGreen} Blue,fontsize=\relsize{-1}}
\DefineVerbatimEnvironment{Sinput}{Verbatim}{fontshape=sl,
formatcom=\color{DarkGreen}}
\newcommand{\rr}[1]{\texttt{\color{DarkGreen} #1}}
\definecolor{DarkGreen}{rgb}{0,0.39216,0}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% declarations for jss.cls - journal of statistical software
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\author{Fraser Ian Lewis, Marta Pittavino, Reinhard Furrer}
\title{Data Modelling using Additive Bayesian Networks}
%\VignetteIndexEntry{A vignette for the abn package}
%% for pretty printing and a nice hypersummary also set:
%% \Plainauthor{, Second Author} %% comma-separated
\Plaintitle{Multidimensional Bayesian regression in R}
\Shorttitle{The \pkg{abn} package}

\Abstract{
This vignette describes the \pkg{abn} package of \proglang{R} which provides functionality for identifying statistical dependencies in complex data using additive Bayesian network models. This methodology is ideally suited for both univariate - one response variable, and multiple explanatory variables - and multivariate analyses, where in both cases all statistical dependencies between all variables in the data are sought. These models comprise of directed acyclic graphs (DAGs) where each node in the graph comprises a generalized linear model, where model search algorithms are used to identify those DAG structures most supported by the data. Currently implemented are models for data comprising of categorical and/or continuous variables. Further relevant information about \pkg{abn} can be found at: \href{http://www.r-bayesian-networks.org}{www.r-bayesian-networks.org}. %\cr\url{http://www.r-bayesian-networks.org}}        
}

\Keywords{\proglang{R}, Bayesian Networks, additive models, structure discovery}
\Plainkeywords{Bayesian Networks, additive models, structure discovery}

\Address{
  Fraser Ian Lewis\\
  Office of Health Economics\\
  United Kingdom, London\\
  E-mail: \email{flewis@ohe.org}\\ 
  
  Marta Pittavino\\
  Institute of Mathematics, University of Zurich\\
  Winterthurerstrasse 270, Zurich 8057, Switzerland\\
  E-mail: \email{marta.pittavino@math.uzh.ch}\\ 
  
  Reinhard Furrer\\
  Institute of Mathematics, University of Zurich\\
  Winterthurerstrasse 270, Zurich 8057, Switzerland\\
  E-mail: \email{reinhard.furrer@math.uzh.ch} 
}

%% need no \usepackage{Sweave.sty}
%%\SweaveOpts{echo=FALSE,keep.source=TRUE}
\SweaveOpts{keep.source=TRUE,echo=FALSE,eps=FALSE,pdf=TRUE,width=11.69,height=8.27,prefix.string=abn_v085}
\newcommand{\deep}{\setlength{\jot}{12pt}}
\newcommand{\nodeep}{\setlength{\jot}{3pt}}
\begin{document}
\SweaveOpts{concordance=TRUE}
\setkeys{Gin}{width=1.0\textwidth}
%----------------------------------------------------------------------------------------
\section{Introduction}
Bayesian network (BN) modeling \citep{ Buntine1991, HECKERMAN1995, Lauritzen1996, Jensen2001} is a form of graphical modeling which attempts to separate out indirect from direct association in complex multivariate data, a process typically referred to as structure discovery \citep{Friedman2003}. Unlike other widely used multivariate approaches where dimensionality is reduced through exploiting linear combinations of random variables, such as in principal component analysis, graphical modeling does not involve any such dimension reduction. Bayesian networks have been developed for analysing multinomial, multivariate Gaussian or conditionally Gaussian networks (a mix categorical and Gaussian variables). A number of libraries for fitting such BNs are available from CRAN. These types of BN have been constructed to ensure conjugacy, that is, enable posterior distributions for the model parameters and marginal likelihood to be calculated analytically. The purpose of \pkg{abn} is to provide a library of functions for more flexible BNs which do not rely on conjugacy, which opens up an extremely rich modeling framework but at some considerable additional computational cost. 

Currently \pkg{abn} includes functionality for fitting non-conjugate BN models which are multi-dimensional analogues of combinations of Binomial (logistic) and Gaussian regression. It includes also model with Poisson (log) distribution for count data and generalised linear models with random effects (with the previous distributions). It is planned to extend this to include more complex distributions for overdispersed data such a beta-binomial and negative binomial.   

The objective in BN modeling structure discovery is to perform a model search on the data to identify an optimal model. Recall that BN models have a vast search space - super-exponential in the number of nodes - and it is generally impossible to determine a globally optimal model. How best to summarize a set of locally optimal networks with different structural features is an open question, and there are a number of widely used and intuitively reasonable possibilities. For example, one option is to conduct a series of heuristic searches and then simply select the best model found \citep{HECKERMAN1995}; alternatively, a single summary network can be constructed using results across many different searches \citep{Hodges2010,Poon2007}. There are obvious pros and cons to either approach and both are common in the literature and provide a good first exploration of the data. For a general non-technical review of BN modeling applied in biology see \citep{Needham2007}. A case study in applying BN models to epidemiological data using the conjugate BN functionality in \pkg{abn} can be found in \citep{Lewis2011}.

In this vignette we consider a series of examples illustrating how to fit different types of models and run different searches and summary analyses to a (synthetic) data set comprising of 250 observations from a joint distribution comprising of 17 categorical and 16 continuous variables which is included as part of the \pkg{abn} library. This data set is a single realization from a network of the same structure as that presented in \citep{Lewis2011}, which is based on real data and sufficiently complex to provide a realistic example of data mining using Bayesian Network modeling. 
Another detailed introduction and further relevant case studies about \pkg{abn} can be found at: \href{http://www.r-bayesian-networks.org}{www.r-bayesian-networks.org}.
 
\section{Case Study Data}
Figure \ref{fig1}
\begin{figure}[htb]
\includegraphics{var33_MASTER}
\vspace{-1.0cm}
\caption{Directed acyclic graph representation of the joint probability distribution which generated data set \rr{var33} which is included with \pkg{abn}. The square nodes are categorical (binary) and the oval nodes continuous variables.} \label{fig1}
\end{figure}
shows the structure of the distribution which generated the data set \rr{var33} included with \pkg{abn}. This diagram was created using the \rr{tographviz()} function of \pkg{abn} (see later examples) which translates the matrix which defines a network - a directed acyclic graph - into a text file of suitable format for processing in Graphviz, where this processing was done outside of \rr{R}. Graphviz is freely available and operates on most platforms and can be downloaded from \href{http://www.graphviz.org}{www.graphviz.org}, there is also an R package which interfaces to Graphviz available from the Bioconductor project (requires an installation of Graphviz). 

\section{Fitting a single BN model to data}
In the next sections we illustrate how to fit a BN model to different kinds of data. The main purpose of BN structure discovery is to estimate the joint dependency structure of the random variables in the available data, and this is achieved by heuristically searching for optimal models and comparing their goodness of fit using Bayes factors. It is assumed that all structures are equally supported in the absence of any data - an uniformative prior on structures - and so comparing Bayes factors collapses to comparing the marginal likelihoods which is done on a log scale. The log marginal likelihood for a BN is typically referred to as the network score. 

\subsection{Fitting an additive BN model to categorical data} \label{sec2}
An additive BN model for categorical data can be constructed by considering each individual variable as a logistic regression of the other variables in the data, and hence the network model comprises of many combinations of local logistic regressions \citep{Rijmen2008}. The parameters in this model are the additive terms in a usual logistic regression and independent Gaussian priors are assumed for each covariate. Note that the variables here must all be binary, and so all multinomial variables need to be split into separate binary factors (and added to the original data.frame) in order to form the network model. This is analogous to forming the design matrix in a conventional additive model analysis. Similarly, interaction terms can be added by including appropriate additional columns in the data.frame. In these models the log marginal likelihood (network score) is estimated using Laplace approximations at each node. Hyperparameters for the means and variances in the Gaussian priors are fixed at zero and 1000 respectively, and other values can be given explicitly in the call to \rr{fitabn} but this is not recommended without good reason.

To fit an additive model use \rr{fitabn(data.df,dag.m,data.dists, ...)}. In the following code we fit first the independence model with no arcs and then the same dependence model as above. Turning on \rr{verbose=TRUE} simply gives the individual log marginal likelihoods for each node (n.b. the numbering is that used internally and simply denotes the variables in the data.frame from left to right).

The following code fits a network to the subset of the variables from \rr{var33} which are categorical. In this data these are all binary. Note that all categorical variables should be set as factors.     
<<echo=TRUE,print=FALSE>>=
library( abn) # load library
bin.nodes<-c( 1,3,4,6,9,10,11,12,15,18,19,20,21,26,27,28,32); 
var33.cat<-var33[,bin.nodes]; #categorical nodes only

mydag<-matrix(c(  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0, #v1
                  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0, #v3
                  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0, #v4  
                  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0, #v6  
                  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0, #v9  
                  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0, #v10  
                  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0, #v11  
                  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0, #v12  
                  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0, #v15  
                  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0, #v18 
                  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0, #v19
                  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0, #v20 
                  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0, #v21 
                  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0, #v26 
                  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0, #v27 
                  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0, #v28 
                  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0  #v32 
               ),byrow=TRUE,ncol=17); 
colnames( mydag)<-rownames( mydag)<-names( var33.cat);#set names
## move back to independence model
mydag["v11","v12"]<-0;mydag["v11","v10"]<-0;mydag["v4","v3"]<-0;
## setup distribution list for each categorical node
mydists.cat<-list( v1 ="binomial", v3 = "binomial",
       v4 = "binomial",  v6 = "binomial",  v9 = "binomial",
      v10 = "binomial", v11 = "binomial", v12 = "binomial",
      v15 = "binomial", v18 = "binomial", v19 = "binomial",
      v20 = "binomial", v21 = "binomial", v26 = "binomial",
      v27 = "binomial", v28 = "binomial", v32 = "binomial");
ind.mod.cat <- fitabn( data.df=var33.cat, dag.m=mydag,
                      data.dists=mydists.cat, verbose=FALSE); 
## change to verbose=TRUE if one want to check how change the 
## score for each individual node
ind.mod.cat$mlik 
## network score for a model with conditional independencies
@
The structure of the network definition matrix is where each row is a ``child'' and each column is its ``parents'', where a \rr{1} denotes a parent (or arc) is present. Now lets fit a model with some conditional dependencies, for example where \rr{v11} is conditionally dependent upon \rr{v12} and \rr{v10}, and \rr{v4} is conditionally dependent upon \rr{v3}.
<<echo=TRUE,print=FALSE>>=
## now fit the model with some conditional dependencies 
mydag["v11","v12"]<-1;mydag["v11","v10"]<-1;mydag["v4","v3"]<-1;
dep.mod.cat <- fitabn( data.df=var33.cat, dag.m=mydag,
                      data.dists=mydists.cat, verbose=FALSE);
dep.mod.cat$mlik
## network score for a model with conditional dependencies
@
The network score is considerably improved and therefore suggests support for these new structural features. To produce a visual description of the model then we can export to graphviz as follows
<<echo=TRUE,print=FALSE>>=
tographviz( dag=mydag, data.df=var33.cat, data.dists=mydists.cat,
           outfile="mydagcat.dot", directed=TRUE);#create file
# mydagcat.dot can then be processed with graphviz
# unix shell "dot -Tpdf mydagcat.dot -o mydagcat.pdf" 
# or use gedit if on Windows
@
\begin{figure}[htb]
\includegraphics{mydag}
\vspace{-1.0cm}
\caption{Directed acyclic graph \rr{mydag} created using \rr{tographviz()} and Graphviz} \label{fig2}
\end{figure}
In \rr{tographviz()} the \rr{data.df} argument is used to determine whether the variable is a factor or not, where factors are displayed as squares and non-factors as ovals. To use the full range of visual Graphviz options simply use the file created by \rr{tographviz()} as a starting point and manually edit this in a text editor before running through \rr{dot} or one of the other Graphviz layout processors.


\subsection{Fitting an additive BN model to continuous data} \label{sec3} 
%{\Large MAKE NEW EDIT - repeated node score values due to standardisation!}
We now consider analogous models to those in Section \ref{sec2} but where the network comprises of Gaussian linear regressions rather than logistic regressions. The structure of these models again assumes independent Gaussian priors for each of the coefficients in the additive components for the mean response at each node (with hyper means = 0 and hyper variances = 1000). The Gaussian response distribution is parameterized in terms of precision $(1/\sigma^2)$, and independent Gamma priors are used with shape=0.001 and scale=1/0.001 (where these are as defined in the \rr{rgamma} help page). By default, each variable in the data.frame is standardised to a mean of zero and standard deviation of one, this has no effect on the identification of dependencies between variables. 
<<echo=TRUE,print=FALSE>>=
var33.cts<-var33[,-bin.nodes]; #drop categorical nodes
mydag<-matrix( 0, 16, 16);
colnames( mydag)<-rownames( mydag)<-names( var33.cts);#set names
## setup distribution list for each continuous node
mydists.cts<-list( v2 = "gaussian", v5 = "gaussian",
        v7 = "gaussian", v8 = "gaussian", v13 = "gaussian", 
        v14 = "gaussian", v16 = "gaussian", v17 = "gaussian",
        v22 = "gaussian", v23 = "gaussian", v24 = "gaussian",
        v25 = "gaussian", v29 = "gaussian", v30 = "gaussian",
        v31 = "gaussian", v33 = "gaussian");
## now fit the model defined in mydag - full independence
ind.mod.cts <- fitabn( data.df=var33.cts, dag.m=mydag,
               data.dists=mydists.cts, verbose=FALSE);
## uses default priors: N(mu=0,var=1000), 1/var=Gamma(0.001,1/0.001)
ind.mod.cts$mlik
# this is the network score=goodness of fit=log marginal likelihood
@
Now fit a model with conditional independencies, for example 
<<echo=TRUE,print=FALSE>>=
# now fit model with some conditional dependencies let v33 
## depend on v31, and v24 depend on 23, and v14 depend on v13
mydag["v33","v31"]<-1;
mydag["v24","v23"]<-1;
mydag["v14","v13"]<-1;
dep.mod.cts <- fitabn( data.df=var33.cts, dag.m=mydag,
               data.dists=mydists.cts, verbose=FALSE);
dep.mod.cts$mlik
# network score for a model with conditional independence
tographviz( dag=mydag, data.df=var33.cts, data.dists=mydists.cts,
            outfile="mydagcts.dot", directed=TRUE);#create file
# mydag.dot can then be processed with graphviz
# unix shell "dot -Tpdf mydagcts.dot -o mydagcts.pdf" or 
# use gedit if on Windows
@
\begin{figure}[htb]
\includegraphics{mydagcts}
\vspace{-1.0cm}
\caption{Directed acyclic graph \rr{mydag} for continuous variables only created using \rr{tographviz()} and Graphviz} \label{fig3}
\end{figure}


\subsection{Fitting an additive BN model to mixed data} \label{sec4}
To conclude the fitting of a single pre-specified model to data, e.g. based on expert opinion, we consider an additive BN model which comprises both binary and Gaussian nodes and this comprises of a combination of Binomial (logistic) and Gaussian linear models. Again \rr{fitabn()} is used and the code is almost identical to the previous examples. 
<<echo=TRUE,print=FALSE>>=
mydag<-matrix( 0, 33, 33); 
colnames( mydag)<-rownames( mydag)<-names( var33);#set names
## setup distribution list for each mixed node
mydists.mix<-list( v1 = "binomial", v2 = "gaussian",
        v3 = "binomial", v4 = "binomial", v5 = "gaussian",
        v6 = "binomial", v7 = "gaussian", v8 = "gaussian",
        v9 = "binomial", v10 = "binomial", v11 = "binomial",
        v12 = "binomial", v13 = "gaussian", v14 = "gaussian",
        v15 = "binomial", v16 = "gaussian", v17 = "gaussian",
        v18 = "binomial", v19 = "binomial", v20 = "binomial",
        v21 = "binomial", v22 = "gaussian", v23 = "gaussian",
        v24 = "gaussian", v25 = "gaussian", v26 = "binomial",
        v27 = "binomial", v28 = "binomial", v29 = "gaussian",
        v30 = "gaussian", v31 = "gaussian", v32 = "binomial",
        v33 = "gaussian");
## now fit the model defined in mydag - full independence
ind.mod <- fitabn( data.df=var33, dag.m=mydag,
          data.dists=mydists.mix, verbose=FALSE);
ind.mod$mlik
# this is the network score with no conditional dependencies
@
We now fit a BN model which has the same structure as the joint distribution used to generate the data and then create a visual graph of this model
<<echo=TRUE,print=FALSE>>=
# define a model with many independencies
mydag[2,1]<-1;
mydag[4,3]<-1;
mydag[6,4]<-1; mydag[6,7]<-1;
mydag[5,6]<-1;
mydag[7,8]<-1;  
mydag[8,9]<-1;
mydag[9,10]<-1;
mydag[11,10]<-1; mydag[11,12]<-1; mydag[11,19]<-1;
mydag[14,13]<-1;
mydag[17,16]<-1;mydag[17,20]<-1;
mydag[15,14]<-1; mydag[15,21]<-1;
mydag[18,20]<-1;
mydag[19,20]<-1;
mydag[21,20]<-1;
mydag[22,21]<-1;
mydag[23,21]<-1;
mydag[24,23]<-1;
mydag[25,23]<-1; mydag[25,26]<-1;
mydag[26,20]<-1;
mydag[33,31]<-1;
mydag[33,31]<-1;
mydag[32,21]<-1; mydag[32,31]<-1;mydag[32,29]<-1;    
mydag[30,29]<-1;
mydag[28,27]<-1; mydag[28,29]<-1;mydag[28,31]<-1;       
dep.mod <- fitabn( data.df=var33, dag.m=mydag, 
           data.dists=mydists.mix, verbose=FALSE);
dep.mod$mlik
# network score for a model with conditional independence
tographviz( dag=mydag, data.df=var33, data.dists=mydists.mix,
            outfile="mydag_all.dot", directed=TRUE);#create file
# mydag.dot can then be processed with graphviz
# unix shell "dot -Tpdf mydag_all.dot -o mydag_all.pdf" or use 
# gedit if on Windows
@
\begin{figure}[htb]
\includegraphics{mydag_all}
\vspace{-1.0cm}
\caption{Directed acyclic graph \rr{mydag} for mixed continuous and discrete variables} \label{fig4}
\end{figure}

\subsection{Model fitting validation}
% In order to validate the conjugate models, network scores for both overall networks and individual nodes using the Bayesian Dirichlet equivalence uniform (BDeu) metric were compared with the \rr{deal} library available from \rr{CRAN}. This metric can be used by \rr{useK2=FALSE} and providing an explicit value for \rr{prior.obs.per.node}. A wide range of models for multinomial data were compared and these were always identical to those values produced by \rr{deal}. 
In order to validate the additive models for mixed binary and Gaussian models, estimates of the posterior distributions for the model parameters using Laplace approximations were compared with those estimated using Markov chain Monte Carlo. These were always in very close agreement for the range of models and data examined. This is an indirect validation of the Laplace estimate of the network score, e.g. if the posterior densities match closely then this implies that the denominator (the marginal likelihood - network score) must also be accurately estimated, as a ``gold standard'' estimate of the network score is generally unavailable for such non-conjugate models. 

\section{Searching for Optimal Models} \label{sec5}
The key objective of the \pkg{abn} library is to enable estimation of statistical dependencies in data comprising of multiple variables - that is, find a DAG which is robust and representative of the dependency structure of the (unknown) stochastic system which generated the observed data. The challenge here is that with such a vast model space it is impossible to enumerate over all possible DAGs, and there may be very many different DAGs with similar goodness of fit. In the next sections we first consider searching for additive (non-conjugate) models. 

\subsection{Single search for optimal additive BN model from categorical data}
To run a single search heuristic use \rr{search.hillclimber()}. This commences from a randomly created DAG which is constructed by randomly adding arcs to an empty network until all possible arcs have been tried. The function \rr{search.hillclimber()} then searches stepwise from the initial random network for an improved structure, where three stepwise operations are possible: i) add an arc; ii) remove and arc; or iii) reverse and arc. The stepwise search is subject to a number of conditions, firstly only moves that do not generate a cycle are permitted, secondly, a parent limit is imposed which fixes the maximum number of parents which each child node can have (arcs go from parent to child), and thirdly it is possible to ban or retain arcs. If provided, \rr{banned.m} is a matrix which defines arcs that are not allowed to be considered in the search process (or in the creation of the initial random network). Similarly, \rr{retain.m} includes arcs which must always be included in any model. It is also possible to specific an explicit starting matrix, \rr{start.m} and if using a retain matrix then \rr{start.m} should contain at least all those arcs present in \rr{retain.m}. Note that only very rudimentary checking is done to make sure that the ban, retain and start networks - if user supplied - are not contradictory.

To improve the computational performance of \rr{search.hillclimber()} a cache of all possible goodness of fit must be built in advance, using the function \rr{buildscorecache()}. Rather than re-calculate the score for each individual node in the network (the overall network score is the product of all the scores for the individual nodes) the score for each unique node found during the search is stored in the cache created by the function \rr{buildscorecache()}.

<<echo=TRUE,print=FALSE,eval=TRUE>>=
bin.nodes<-c(1,3,4,6,9,10,11,12,15,18,19,20,21,26,27,28,32); 
var33.cat<-var33[,bin.nodes];#categorical nodes only
mydag<-matrix( 0, 17, 17); 
colnames(mydag)<-rownames(mydag)<-names(var33.cat);#set names
## create banned and retain empty DAGs
banned.cat<-matrix( 0, 17, 17);
colnames(banned.cat)<-rownames(banned.cat)<-names(var33.cat);
retain.cat<-matrix( 0, 17, 17);
colnames(retain.cat)<-rownames(retain.cat)<-names(var33.cat);
## setup distribution list for each categorical node
mydists.cat<-list( v1 ="binomial", v3 = "binomial",
       v4 = "binomial",  v6 = "binomial",  v9 = "binomial",
      v10 = "binomial", v11 = "binomial", v12 = "binomial",
      v15 = "binomial", v18 = "binomial", v19 = "binomial",
      v20 = "binomial", v21 = "binomial", v26 = "binomial",
      v27 = "binomial", v28 = "binomial", v32 = "binomial");
## build cache of all the local computations
## this information is needed later when running a model search
mycache.cat<-buildscorecache( data.df=var33.cat,
             data.dists=mydists.cat, dag.banned=banned.cat, 
             dag.retained=retain.cat, max.parents=1);
@

Running a single search heuristic for an additive BN uses \rr{search.hillclimber()}. It uses a parameter prior specifications (as detailed above). Several additional arguments are available which relate to the numerical routines used in the Laplace approximation to calculate the network score. The defaults appear to work reasonably well in practice and if it is not possible to calculate a robust value for this approximation in any model, for example due to a singular design matrix at one or more nodes, then the model is simply assigned a log network score of $-\infty$ which effectively removes it from the model search.  

<<echo=TRUE,print=FALSE,eval=FALSE>>=
# Run a single search heuristic for an additive BN
heur.res.cat<-search.hillclimber( score.cache=mycache.cat,
              num.searches=1, seed=0, verbose=FALSE,
              trace=FALSE, timing.on=FALSE);
# Setting trace=TRUE, the majority consensus network is 
# plotted as the searches progress
@

\subsection{Single search for optimal  additive BN model for continuous data} \label{sec4a}
As above but for a network of Gaussian nodes.
<<echo=TRUE,print=FALSE,eval=TRUE>>=
var33.cts<-var33[,-bin.nodes];#drop categorical nodes
mydag<-matrix( 0, 16, 16); 
colnames(mydag)<-rownames(mydag)<-names(var33.cts);#set names
banned.cts<-matrix( 0, 16, 16);
colnames(banned.cts)<-rownames(banned.cts)<-names(var33.cts);
retain.cts<-matrix( 0, 16, 16);
colnames(retain.cts)<-rownames(retain.cts)<-names(var33.cts);
## setup distribution list for each continuous node
mydists.cts<-list( v2 = "gaussian", v5 = "gaussian",
        v7 = "gaussian", v8 = "gaussian", v13 = "gaussian", 
        v14 = "gaussian", v16 = "gaussian", v17 = "gaussian",
        v22 = "gaussian", v23 = "gaussian", v24 = "gaussian",
        v25 = "gaussian", v29 = "gaussian", v30 = "gaussian",
        v31 = "gaussian", v33 = "gaussian");
## build cache of all the local computations
## this information is needed later when running a model search
mycache.cts<-buildscorecache( data.df=var33.cts,
             data.dists=mydists.cts, dag.banned=banned.cts,
             dag.retained=retain.cts, max.parents=1);
@
<<echo=TRUE,print=FALSE,eval=FALSE>>=
# Run a single search heuristic for an additive BN
heur.res.cts<-search.hillclimber( score.cache=mycache.cts,
              num.searches=1, seed=0, verbose=FALSE,
              trace=FALSE, timing.on=FALSE);
# Setting trace=TRUE, the majority consensus network is
# plotted as the searches progress
@

\subsection{Single search for optimal additive BN model for mixed data}
Model searching for mixed data is again very similar to the previous examples. Note that in this example the parameter priors are specified explicitly (although those given are the same as the defaults). The \rr{+1} in the hyperparameter specification is because a constant term is included in the additive formulation for each node.

<<echo=TRUE,print=FALSE,eval=TRUE>>=
mydag<-matrix( 0, 33, 33); 
colnames(mydag)<-rownames(mydag)<-names(var33);#set names
## create empty DAGs
banned.mix<-matrix( 0, 33, 33);
colnames(banned.mix)<-rownames(banned.mix)<-names(var33);
retain.mix<-matrix( 0, 33, 33);
colnames(retain.mix)<-rownames(retain.mix)<-names(var33);
## setup distribution list for mixed node
mydists.mix<-list( v1 = "binomial", v2 = "gaussian",
        v3 = "binomial", v4 = "binomial", v5 = "gaussian",
        v6 = "binomial", v7 = "gaussian", v8 = "gaussian",
        v9 = "binomial", v10 = "binomial", v11 = "binomial",
        v12 = "binomial", v13 = "gaussian", v14 = "gaussian",
        v15 = "binomial", v16 = "gaussian", v17 = "gaussian",
        v18 = "binomial", v19 = "binomial", v20 = "binomial",
        v21 = "binomial", v22 = "gaussian", v23 = "gaussian",
        v24 = "gaussian", v25 = "gaussian", v26 = "binomial",
        v27 = "binomial", v28 = "binomial", v29 = "gaussian",
        v30 = "gaussian", v31 = "gaussian", v32 = "binomial",
        v33 = "gaussian");
## build cache of all the local computations
## this information is needed later when running a model search
mycache.mix<-buildscorecache( data.df=var33,
             data.dists=mydists.mix, dag.banned=banned.mix,
             dag.retained=retain.mix, max.parents=1);
# Run a single search heuristic for an additive BN
heur.res.mix<-search.hillclimber( score.cache=mycache.mix,
              num.searches=1, seed=0, verbose=FALSE,
              trace=FALSE, timing.on=FALSE);
# Setting trace=TRUE, the majority consensus network is 
# plotted as the searches progress
@


\section{Multiple Search Strategies}
To estimate a robust additive BN for a given dataset is it necessary to run many searches and then summarize the results of these searches. The function \rr{search.hillclimber()} \\
with \rr{num.searches>1} run multiple searches. It is necessary to use a single joint node cache over all  searches, using the function \rr{buildscorecache}.

Conceptually it may seem more efficient to use one global node cache to allow node information to be shared between different searches, however, in practice as the search space is so vast for some problems this can result in extremely \emph{slow} searches. As the cache becomes larger it can take much more time to search it (and it may need to be searched a very large number of times) than to simply perform the appropriate numerical computation. Profiling using the google performance tool google-pprof suggests that more than 80\% of the computation time may be taken up by lookups. When starting searches from different random places in the model space the number of individual node structures in common between any two searches, relative to the total number of different node structures searched over can be very small meaning a common node cache is inefficient. This may not be the case when starting networks are relatively similar.   

To help with performance monitoring it is possible to turn on timings using \rr{timing.on=TRUE} which then outputs the number of seconds of CPU time each individual search takes (using standard libc functions declared in time.h).

<<echo=TRUE,print=FALSE,eval=TRUE>>=
mydag<-matrix( 0, 33, 33); 
colnames(mydag)<-rownames(mydag)<-names(var33);#set names
## create empty DAGs
banned.mix<-matrix( 0, 33, 33);
colnames(banned.mix)<-rownames(banned.mix)<-names(var33);
retain.mix<-matrix( 0, 33, 33);
colnames(retain.mix)<-rownames(retain.mix)<-names(var33);
## setup distribution list for mixed node
mydists.mix<-list( v1 = "binomial", v2 = "gaussian",
        v3 = "binomial", v4 = "binomial", v5 = "gaussian",
        v6 = "binomial", v7 = "gaussian", v8 = "gaussian",
        v9 = "binomial", v10 = "binomial", v11 = "binomial",
        v12 = "binomial", v13 = "gaussian", v14 = "gaussian",
        v15 = "binomial", v16 = "gaussian", v17 = "gaussian",
        v18 = "binomial", v19 = "binomial", v20 = "binomial",
        v21 = "binomial", v22 = "gaussian", v23 = "gaussian",
        v24 = "gaussian", v25 = "gaussian", v26 = "binomial",
        v27 = "binomial", v28 = "binomial", v29 = "gaussian",
        v30 = "gaussian", v31 = "gaussian", v32 = "binomial",
        v33 = "gaussian");
n.searches<- 10; # example only - must be much larger in practice
## parent limits
max.par<-1 #only 1 because take some minutes for buildscorecache()
## now build cache
mycache.mix<-buildscorecache(data.df=var33, data.dists=mydists.mix,
dag.banned=banned.mix, dag.retained=retain.mix, max.parents=max.par)
# repeat but this time have the majority consensus network plotted 
# as the searches progress
myres.mlp<-search.hillclimber(score.cache=mycache.mix,
           num.searches=n.searches, seed=0, verbose=FALSE,
           trace=FALSE, timing.on=FALSE);
@
\subsection{Creating a Summary Network - Majority Consensus}\label{mcn}
Having run many heuristic searches, then the next challenge is to summarise these results to allow for ready identification of the joint dependencies most supported by the data. One common, and very simple approach is to produce a single robust BN model of the data mimicing the approach used in phylogenetics to create majority consensus trees. A majority consensus DAG is constructed from all the arcs present in at least 50\% of the locally optimal DAGs found in the search heuristics. This creates a single summary network. Combining results from different runs of \rr{search.hillclimber()} or \rr{search.hillclimber()} is straightforward, although note that it is necessary to check for duplicate random starting networks, as while highly unlikely this is theoretically possible. The following code provides a simple way to produce a majority consensus network and Figure \ref{fig5} shows the resulting network - note that this is an example only and many thousands of searches may need to be conducted to achieve robust results. One simple ad-hoc method for assessing how many searches are needed is to run a number of searches and split the results into two (random) groups, and calculate the majority consensus network within each group. If these are the same then it suggests that sufficient searches have been run.   
To plot the majority consensus network use the result of the function \rr{search.hillclimber}, see below for some example.

\begin{figure}[htb]
\includegraphics{dagcon}
\vspace{-1.0cm}
\caption{Example majority consensus network (from the results of only 10 searches)} \label{fig5}
\end{figure}

 
<<echo=TRUE,print=FALSE,eval=TRUE>>=
tographviz(dag= myres.mlp$consensus, data.df=var33,
data.dists=mydists.mix, outfile="dagcon.dot");#create file
# dagcon.dot can then be processed with graphviz
# unix shell "dot -Tpdf dagcon.dot -o dagcon.pdf" or use 
# gedit if on Windows
@

\section{Creating a Summary Network - Pruning}
Rather than use the majority consensus network as the most appropriate model of the data, an alternative approach is to choose the single best model found during a large number of searches. To determine sufficient heuristic searches have been run to provide reasonable coverage of all the features of the model landscape, then again checking for a stable majority consensus network as in Section \ref{mcn}, seems a sensible approach. Once the best overall DAG has been identified then the next task is to check this model for over-fitting. Unlike with the majority consensus network, which effective ``averages'' over many different competing models and therefore should generally comprise only robust structural features, choosing the DAG from a single model search is far more likely to contain some spurious features. When dealing with smaller data sets, say, of several hundred observations then this is extremely likely, as can easily be demonstrated using simulated data. A simple assessment of overfitting can be made by comparing the number of arcs in the majority consensus network with the number of arcs in the best fitting model. We have found that in larger data sets the majority consensus and best fitting model can be almost identical, while in smaller data sets the best fitting models may have many more arcs - suggesting a degree of overfitting. 

An advantage of choosing a DAG from an individual search is that unlike averaging over lots of different structures, as in the construction of a majority consensus network, the model chosen here has a structure which was actually found during a search across the model landscape. In contrast, the majority consensus network is a derived model which may never have been found chosen during even an exhaustive search, indeed it may even comprise of contradictory features as is a usual risk in averaging over different explanations (models) of data. In addition, a majority consensus network need also not be acyclic, although in practice this can be easily corrected by reversing one or more arcs to produce an appropriate DAG.

A simple compromise between the risk of over-fitting in choosing the single highest scoring DAG, and the risk of inappropriately averaging across different distinct data generating processes, is to prune the highest scoring DAG using the majority consensus model. In short, an element by element multiply of the highest scoring DAG and the majority consensus DAG, which gives a new DAG which only contains the structural features in \emph{both} models. 

\section{Creating a Summary Network - Parametric Bootstrapping}   
In \citep{Friedman1999} a general approach for using parametric bootstrapping to select BN models/DAG structures was presented. Such approaches can be reasonably easily implemented by using readily available Markov chain Monte Carlo sampling software such as JAGS or WinBUGS. The basic idea is to take the structure with the best network score and then code it up in either JAGS or WinBUGS, and use these samplers to generate bootstrap data sets from this model. That is, independent realisations from the model which can be used to generate a data set of the same size as the observed data. Given this bootstrap data, then the BN model search is repeated treating this as the observed data. By generating many bootstrap data sets and conducting searches on each, then this allows us to estimate the percentage support for each arc in the highest scoring model. Another way to put this is that we find out how many of the arcs in the highest scoring model can be ``recovered'' from a data set of the size as that actually observed. Obviously, the more data, the more statistical power, and the more structural features which can be recovered. For arcs with a lower level of support, e.g. <50\%, then these can be pruned from the best fitting model, the assumption being that these are potentially as a result of overfitting. The resulting model - possibly with arcs pruned off from the original model - is then our chosen model of the data. 

Using a 50\% threshold for arc support is intuitively reasonable as can be seen by considering a model of a single node. Suppose there are two covariates, and the ``response'' variable (the node) is almost deterministically dependent with each of these variables (that is overwhelming statistical support), and that the two covariates are almost exactly collinear. In which case only one arc will be needed in the model, and running random restart heuristic searches in this case will result in approximately 50\% of search results suggesting an arc from covariate one to the response variable, and the other 50\% for an arc from covariate two to the response variable. Therefore,  despite the fact that each of these variables is almost surely (with probability=1) dependent with the response variable each arc cannot exceed 50\% support. This is an idealized example but provides an intuitive argument as to why 50\% is a reasonable threshold above which we can be fairly confident that the arcs may be a real, rather than spurious statistical feature. 

While parametric bootstrapping is a general technique is well established and conceptually elegant, this may in practice not be computationally feasible. Even if taking the least demanding approach of conducting only one heuristic search per bootstrap data set, the number of data sets/searches required in order to get robust \% support values for each arc in the best fitting model may be large, and beyond what is reasonably possible even using high performance computing (HPC) hardware. We would suggest that it is at least good practice to investigate the feasibility of this approach. To that end we next outline how to perform parametric bootstrapping using \pkg{abn} and \rr{JAGS} and all the relevant source files are included in the \rr{abn/bootstrapping\_example} library subdirectory.


\subsection{Steps Necessary to Perform Parametric Bootstrapping}
Given a BN model - DAG structure plus parameter priors - then the first step is to estimate the posterior parameters. The second step is to implement the DAG structure together with the posterior parameters into the language used by \rr{JAGS}, which is very similar to that used in \rr{WinBUGS}. Generally speaking, the posterior parameters in an additive BN model need not conform to any standard probability distribution as these are non-conjugate models. To make the implementation as general as possible, rather than, for example, attempting to match each posterior distribution to, say, the closest shaped Gaussian density, we present an approach which allows all posterior parameters to be from a non-standard - bespoke - distribution. This is implemented in \rr{JAGS} by discretising each posterior density across a fine grid and using a discrete sampler, \rr{dcat()} in \rr{JAGS}.   

\subsubsection{Estimating Posterior Densities}
The function \rr{fitabn()} with \rr{compute.fixed=TRUE} uses Laplace approximations to estimate the posterior density of each parameter in a BN model. An appropriate domain (range) for each parameter \emph{must} be supplied by the user which is done by some trial and error to find where about on the real line the density resides - it will be close to the origin either through the use of a logistic link function or through the standardisation of the Guassian node. An initial guess of (-2,2) is often a good starting point. It is crucially important that a sufficiently wide range is given so that ``all'' of the upper and lower tails of the distribution are included, e.g. the range should be where an R density plot first drops to approximately zero at each tail. Note that \rr{fitabn()} works with one node and one parameter in that node at a time. It is not necessary - but does no harm - to specify the full DAG, but all that is needed is the node and its parents.  

We now follow the example contained in the \rr{abn/bootstrapping\_example} library subdirectory. We use a second data set included with \pkg{abn}, called \rr{pigs.1par} which is again a synthetic dataset generated from analyses of real data. The first step is define the model of interest, \rr{mydag}, and then  estimate the posterior densities. The posterior parameters calculated are the marginal effects, that is all other model parameters (at the given node) are integrated out. At each node - which is defined using argument \rr{marginal.node} - the intercept term can be estimated using \rr{marginal.param=1} (see below) and for Gaussian nodes the precision parameter can be estimated using \rr{prec}. The remaining parameters are the mean covariate effects, for example using \rr{marginal.node=1} and \rr{marginal.param=2} in \rr{fitabn()} gives the posterior marginal density for covariate \rr{D2} for the response variable \rr{D1}. Note that by default all Gaussian variables are standardised to a mean of zero and a standard deviation of one. 

<<echo=TRUE,print=FALSE,eval=TRUE>>=
#specific a DAG model - the model we wish to use to perform 
#parametric bootstrapping
mydag.pigs<-matrix(c( 
# D1 D2 D3 D4 D5 D6 D7 D8 D9 D10 Year Loc.x Loc.y
  0, 1, 0, 0, 0, 0, 0, 0, 0, 0,  0,   0,    0,    # D1
  0, 0, 1, 0, 0, 0, 0, 0, 0, 0,  0,   0,    0,    # D2
  0, 0, 0, 1, 0, 0, 0, 0, 0, 0,  0,   0,    0,    # D3
  0, 0, 0, 0, 0, 0, 0, 0, 0, 0,  0,   1,    0,    # D4
  0, 0, 0, 0, 0, 1, 0, 0, 0, 0,  0,   0,    0,    # D5
  0, 0, 0, 1, 0, 0, 0, 0, 0, 0,  0,   0,    0,    # D6
  0, 0, 0, 0, 0, 0, 0, 0, 0, 0,  1,   0,    0,    # D7
  0, 0, 0, 0, 0, 0, 0, 0, 0, 1,  0,   0,    0,    # D8
  0, 1, 0, 0, 0, 0, 0, 0, 0, 0,  0,   0,    0,    # D9
  0, 0, 0, 0, 0, 0, 0, 0, 1, 0,  0,   0,    0,    # D10
  0, 0, 0, 0, 0, 0, 0, 0, 0, 0,  0,   0,    0,    # Year
  0, 0, 0, 0, 0, 0, 1, 0, 0, 0,  0,   0,    0,    # Loc.x
  0, 0, 0, 0, 0, 0, 1, 0, 0, 0,  0,   0,    0     # Loc.y
               ),byrow=TRUE,ncol=13); 
colnames(mydag.pigs)<-rownames(mydag.pigs)<-names(pigs.1par);
## setup distribution list for each "pigs" node
mydists.pigs <- list( D1 = "binomial", D2 = "binomial",
        D3 = "binomial", D4 = "binomial", D5 = "binomial",
        D6 = "binomial", D7 = "binomial", D8 = "binomial",
        D9 = "binomial", D10 = "binomial", Year = "gaussian",
        Loc.x = "gaussian", Loc.y = "gaussian");
# Node D1|D2 e.g. logit(P(D1=TRUE)=constant+coeff*D2
# first get the posterior density for the constant and
# get grid of discrete values x and f(x)
marg.D1.1<-fitabn( data.df=pigs.1par, dag.m=mydag.pigs,
           data.dists=mydists.pigs, compute.fixed=TRUE,
           marginal.node=1, marginal.param=1, # intercept
           variate.vec=seq(from=1,to=1.7,len=1000),
           verbose=FALSE, n.grid=1000);
print(names(marg.D1.1$marginals));
# now repeat for the slope term coeff
marg.D1.2<-fitabn( data.df=pigs.1par, dag.m=mydag.pigs,
           data.dists=mydists.pigs, compute.fixed=TRUE,
           marginal.node=1, marginal.param=2, # slope
           variate.vec=seq(from=0.6,to=1.5,len=1000),
           verbose=FALSE, n.grid=1000);
print(names(marg.D1.2$marginals));
@
The parameters can be estimated one at a time by manually giving a grid. We plot the marginal posterior densities for node D1 with one parent, the covariate D2, as in the following model:
%\\-4mm]
\begin{center}
logit$\left\{P(\mbox{D3}=1)\right\}=\textcolor{brown}{\beta_{D1,0}}+\textcolor{blue}{\beta_{D1,1}}\cdot \mbox{D2}$ 
\end{center}
\begin{figure}[htbp]
<<newfile,echo=TRUE,eval=TRUE,fig=TRUE>>=
par( mar=c(8.8,8.2,3.1,3.1),mgp=c(4,2,0));
par( cex.axis=2,cex.lab=2,cex.main=2);
par( las=1,xaxs="i",yaxs="i");
plot( marg.D1.1$marginals[["D1|(Intercept)"]],xlab="Log odds",
      ylab="Density",type="l",axes=!FALSE,xlim=c(0,2), 
      ylim=c(0,7),col="brown",lwd=3,lty=1);
lines( marg.D1.2$marginals[["D1|D2"]],
      col="blue",lwd=3,lty=6);
legend( "topleft",legend=c(expression(paste("f(",beta[D1*","~0],
            "|D)= intercept node D1",sep="")), 
        expression(paste("f(",beta[D1*","~1],
            "|D)= effect of D2 at node D1",sep=""))), cex=1.5, 
        col=c("brown","blue"),lty=c(1,6),lwd=5, bty='n');
@
\caption{Posterior densities for intercept and slope in node D1 in pigs.1par} \label{fig6}
\end{figure}
Figure \ref{fig6} shows an example of posterior densities estimated using \rr{fitabn()}, all posterior densities for all parameters in the additive BN can be estimated in the same way.

%\newpage
The file \rr{calculate\_marginalDensities.R} in \rr{abn/bootstrapping\_example} contains R code for estimating all the marginal parameters in the DAG \rr{mydag} given above. This file is documented. It calculates all the marginal distributions and then writes them out to a file \rr{post\_params.R} which is in the R dump format which can be read into {JAGS}.

The remaining files are \rr{script1.R} which is the script which runs the \rr{JAGS} MCMC sampling. The \rr{JAGS} package is open source and can be downloaded from sourceforge along with appropriate documentation. The file \rr{simulate\_1par.bug} contains the DAG implemented into the \rr{JAGS} language along with the posterior parameter estimates, the creation of this file is the main task involved in the parameteric bootstrapping. Once the \rr{script1.R} has completed (this script is run simply by typing \rr{jags script1.R} at the command line), then the bootstrap data set generated is contained in the file \rr{outchain1.txt} and \rr{outchain2.txt}. Running two (or more) chains allows for checking of convergence. The script is set up to generate 10000 realisations, to get a single bootstrap data set we would trim this down to 9011 observations which is that same size as the original data \rr{pigs.1par}. Once we have this bootstrap data set then we simply run a model search on this, for example using \rr{search.hillclimber()} as detailed above.  

To automate the parametric bootstrapping one option is to edit the \rr{script1.R} so that sufficient realisations are generated to create many independent bootstrap data sets, for example generate 1000 $\times$ 9011 realisations.\\
For a better overview of the automatization procedure, refer to the website \href{http://www.r-bayesian-networks.org}{www.r-bayesian-networks.org}, in particular see the section "Case Studies/ Case Study One/ Automating for use on a cluster".

\section{Order Based Searches}
It is generally not feasible to iterate over all possible DAG structures when dealing with more than a handful of variables, hence the reliance on heuristic searches. It is also extremely difficult to construct efficient Monte Carlo Markov chain samplers across BN structures. A solution to this was proposed in \citep{Friedman2003} where rather than sample across DAGs, it was proposed to sample across node orderings. A node order is simply the set of integers $1$ through $n$, where $n$ is the number of variables in the data. A DAG is consistent with an ordering if for each node in the order its parents come before it. For example a DAG with only an arc from 1$\rightarrow$2 is consistent with ordering $1,2,3,4$ as the parent $1$ comes before $2$, but a DAG with an arc from 2$\rightarrow$1 is not consistent with this ordering. In effect, each order is a collection of DAGs, and note that each DAG may be consistent with multiple orders, i.e. the empty DAG is consistent with every possible ordering. This introduces bias, in that averaging across orders need not give the same results as averaging across DAGs, if the latter were possible. This is relevant when estimating posterior probabilities of individual structural features, and is baised towards more parsimonious features as they are consistent with more orders. Note that this bias does not apply to maximising across orders, as in finding most probable structures (see later). The big advantage of searching across orders is that there are $n!$ different orders compared to a reasonably tight upper bound of $2^{ n \choose 2 }$ for different DAGs.  

There are (at least) two approaches for searching across orders. The first is to construct a Markov chain which samples from the posterior distribution of all orders, and is the approach presented in \citep{Friedman2003}. Alternatively, in \citep{Koivisto2004} an exact method is proposed which rather than sample across orders, performs an exhaustive search. This has the advantage that it can also be used to find the globally optimal DAG of the data - the most probable structure - as well as posterior probabilities for structural features, such as individual arcs. The drawback is that this exact approach is only feasible with smaller number of variables e.g. up to 12 or 13 when dealing with additive models. For the code provided in \pkg{abn} this exact approach is readily feasible up to 20 variables using typical desktop computing, and potentially up to 25 variable with access to a shared memory cluster computer. 

 
\subsection{Most Probable Structure}
Using the exact order based method due to \citep{Koivisto2004} it is also possible to identify the DAG with globally best network score. Identification of a most probable structure is split into two parts. Firstly we calculate a cache of individual node scores, for example using \rr{buildscorecache()}. Next, an exhaustive order based structural search is carried out using the function \rr{mostprobable} which relies on the information in the node cache. 

As in the heuristic searches it is possible to ban or retain certain arcs, for example when splitting multinomial variables. This is done in the node cache computation step. There are two different structural priors implemented in this search, the first in the uniform prior where all structures (all parent combinations) are equally likely. This is the default \rr{prior.choice=1} in \rr{mostprobable} and the other functions. Also implemented is the prior used in \citep{Koivisto2004} where all parent combinations of equal cardinality are equally weighted, this is \rr{prior.choice=2}. The latter does give the same prior weight to a parent combination with no parents and a parent combination comprising off all possible parents (since there is only one choice of each, n-1 choose 0 and n-1 choose n-1). This may not be desirable but is included as a prior for completness. Note that the order based search is exact in the sense that it will identify a DAG who score is equal to the best possible score if it was possible to exhaustive search across all DAGs. For example, if using \rr{prior.choice=1} then the network found should have a score greater than or equal to that found using the previously described heuristic searches. The structure found need not be unique in that others may exist with the same globally optimal score, the order based search is only guaranteed to find one such structure.

To calculate the most probable structure we again use \rr{buildscorecache()} to calculate a cache of individual node scores. Next, the function \rr{mostprobable()} does the actual exhaustive order based search, and works for both conjugate and additive models since as with calculating
the posterior probabilities this step only involves structural searching and is not concerned with the precise parameterisation of each BN model.

Below are some examples of how to find the most probable structure - these are very small examples, but work identical for larger data sets, but with considerably increased computational time. The low memory versions give copius output so its possible to see what is happening during execution - these are only designed for use of larger problems e.g. 20+ variables.

<<echo=TRUE,print=FALSE,eval=TRUE>>=
pigs<-pigs.1par[,c(1:8,12,13)];
# all 9011 observation but limit to 10 variables
# using all 13 variables in pigs will take several
# hours of cpu time
max.par <- 1
# setup the distribution for each "pigs subset nodes
mydists.pigs.sub <- list( D1 = "binomial", D2="binomial",
        D3 = "binomial", D4 = "binomial", D5 = "binomial",
        D6 = "binomial", D7 = "binomial", D8 = "binomial",
        Loc.x = "gaussian", Loc.y = "gaussian");
banned.pigs.sub<-matrix( 0, 10, 10);#banlist with no constraints
colnames(banned.pigs.sub)<-rownames(banned.pigs.sub)<-names(pigs);
retain.pigs.sub<-matrix( 0, 10, 10);#retainlist without constraints
colnames(retain.pigs.sub)<-rownames(retain.pigs.sub)<-names(pigs);
#compute node cache - note restriction of max. 1 parent 
# per node, this should be increased as necessary
system.time( mynodes.add<-buildscorecache( data.df=pigs,
       data.dists=mydists.pigs.sub, max.parents=max.par,
       dag.banned=banned.pigs.sub, dag.retained=retain.pigs.sub));
# now find the globally best model using previous node cache - so 
# we are only looking for the best DAG, most probable network, 
# within the scope of no more than one parent per node
map.1par.10var<-mostprobable( score.cache=mynodes.add);
tographviz(dag=map.1par.10var,data.df=pigs,
           data.dists=mydists.pigs.sub,
           outfile="map1_10var.dot");#create file
# map1_10var.dot can then be processed with graphviz
# unix shell "dot -Tpdf map1_10var.dot -o map1_10var.pdf" or 
# use gedit if on Windows
@
\begin{figure}[htbp]
\centering
\includegraphics[width=8cm]{map1_10var.pdf}
\vspace{-1.0cm}
\caption{Most probable DAG for data in pigs.1par with variables D1-D8, Loc.x and Loc.y, and after imposing a limit of no more than one parent per node} \label{fig7}
\end{figure}

Figure \ref{fig7} shows a most probable DAG using a subset of variables from pigs.1par and a parent limit of one per node.

<<echo=TRUE,print=FALSE,eval=TRUE>>=
pigs.all<-pigs.1par;#all observations all variables
## setup distribution list for each node
mydists.pigs <- list( D1 = "binomial", D2 = "binomial",
        D3 = "binomial", D4 = "binomial", D5 = "binomial",
        D6 = "binomial", D7 = "binomial", D8 = "binomial",
        D9 = "binomial", D10 = "binomial", Year = "gaussian",
        Loc.x = "gaussian", Loc.y = "gaussian");
banned.pigs <- matrix( 0, 13, 13);
colnames(banned.pigs)<-rownames(banned.pigs)<-names(pigs.all);
retain.pigs <-  matrix( 0, 13, 13);
colnames(retain.pigs)<-rownames(retain.pigs)<-names(pigs.all);
system.time( mynodes.add.all<-buildscorecache( data.df=pigs.all,
        max.parents=1, data.dists=mydists.pigs,
        dag.banned=banned.pigs, dag.retained=retain.pigs));
## now for most probable network of all DAGs where each node has 
## at most one arc
system.time( map.1par<-mostprobable( score.cache=mynodes.add.all, 
                                    prior.choice=1));
tographviz( dag=map.1par,data.df=pigs.all, data.dists=mydists.pigs,
           outfile="map_1par.dot");#create file
# mydag.dot can then be processed with graphviz
# unix shell "dot -Tpdf map_1par.dot -o map_1par.pdf" or use gedit 
# if on Windows 
@

\begin{figure}[htb]
%\vspace{-2cm}
\centering
\includegraphics[width=8cm]{map_1par}%\\[-2cm]
%\vspace{-1.5cm}
\caption{Most probable DAG for data in pigs.1par imposing a limit of no more than one parent per node} \label{fig8}
\end{figure}

Figure \ref{fig8} shows the most probable DAG considering all variables in pigs.1par and a parent limit of one per node. 
%This took 6520 seconds (\approx 1.8hrs) to complete on an 3Ghz Intel Xeon CPU, and the run time may increase dramatically for more variables and an increased parent limit.

\clearpage
\section{Summary}
The \pkg{abn} library provides a range of Bayesian network models to assist with identifying statistical dependencies in complex data, in particular models which are multidimensional analogues of generalised linear models. This process is typically referred to as structure learning, or structure discovery, and is computational extremely challenging. Heuristics are the only options for data comprising of larger numbers of variables. As with all model selection, over-modelling is an everpresent danger and using either: i) summary models comprising of structural features present in many locally optimal models or else; ii) using parametric bootstrapping to determine the robustness of the features in a single locally optimal model are likely essential to provide robust results. An alternative presented was exact order based searches, in particular finding the globally most probable structure. This approach is appealing as it is exact, but despite collapsing DAGs into orderings for larger scale problems it may not be feasible.
For further in-depth analysis about \pkg{abn} refer to the website: \href{http://www.r-bayesian-networks.org}{www.r-bayesian-networks.org}.

\newpage
\bibliography{abn}

\end{document}
