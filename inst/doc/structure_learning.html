<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />



<title>Bayesian Network Structure Learning</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>



<style type="text/css">
code {
white-space: pre;
}
.sourceCode {
overflow: visible;
}
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
{ counter-reset: source-line 0; }
pre.numberSource code > span
{ position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
{ content: counter(source-line);
position: relative; left: -1em; text-align: right; vertical-align: baseline;
border: none; display: inline-block;
-webkit-touch-callout: none; -webkit-user-select: none;
-khtml-user-select: none; -moz-user-select: none;
-ms-user-select: none; user-select: none;
padding: 0 4px; width: 4em;
color: #aaaaaa;
}
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }
div.sourceCode
{ }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } 
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.at { color: #7d9029; } 
code span.bn { color: #40a070; } 
code span.bu { color: #008000; } 
code span.cf { color: #007020; font-weight: bold; } 
code span.ch { color: #4070a0; } 
code span.cn { color: #880000; } 
code span.co { color: #60a0b0; font-style: italic; } 
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.do { color: #ba2121; font-style: italic; } 
code span.dt { color: #902000; } 
code span.dv { color: #40a070; } 
code span.er { color: #ff0000; font-weight: bold; } 
code span.ex { } 
code span.fl { color: #40a070; } 
code span.fu { color: #06287e; } 
code span.im { color: #008000; font-weight: bold; } 
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.kw { color: #007020; font-weight: bold; } 
code span.op { color: #666666; } 
code span.ot { color: #007020; } 
code span.pp { color: #bc7a00; } 
code span.sc { color: #4070a0; } 
code span.ss { color: #bb6688; } 
code span.st { color: #4070a0; } 
code span.va { color: #19177c; } 
code span.vs { color: #4070a0; } 
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } 
</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>



<style type="text/css">

div.csl-bib-body { }
div.csl-entry {
clear: both;
}
.hanging div.csl-entry {
margin-left:2em;
text-indent:-2em;
}
div.csl-left-margin {
min-width:2em;
float:left;
}
div.csl-right-inline {
margin-left:2em;
padding-left:1em;
}
div.csl-indent {
margin-left: 2em;
}
</style>

<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Bayesian Network Structure Learning</h1>



<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="fu">library</span>(abn)</span></code></pre></div>
<p>With this vignette we aim to provide a basic introduction to the
structure learning of Bayesian networks with the <code>abn</code>
package.</p>
<div id="structure-learning-of-bayesian-networks" class="section level1">
<h1>Structure Learning of Bayesian Networks</h1>
<p>The structure learning of Bayesian networks is the process of
estimating the (in-)dependencies between the variables of the network
that results in a directed acyclic graph (DAG) where the nodes represent
the variables and the edges represent the dependencies between the
variables. Structure learning of Bayesian networks is a challenging
problem and there are several algorithms to solve it (see <span class="citation">Koller and Friedman (2009)</span> for a comprehensive
review).</p>
<p>The <code>abn</code> package currently offers four distinct
algorithms for Bayesian network structure learning:</p>
<ul>
<li><p><code>mostProbable()</code>: This exact order-based structure
learning algorithm identifies the most probable posterior DAG following
the method of <span class="citation">Koivisto and Sood (2004)</span>.
For details see the help page of <code>mostProbable()</code>.</p></li>
<li><p><code>searchHillClimber()</code>: The Hill-climber algorithm is a
single move algorithm. At each step, an arc is attempted to be added.
The new score is computed and compared to the previous network’s score.
It deviates slightly from the original method proposed by <span class="citation">Heckerman, Geiger, and Chickering (1995)</span> by
utilizing a full cache of all possible local combinations as provided by
<code>buildScoreCache()</code>. The algorithm considers all potential
single swaps in the DAG at each step, selecting the swap that maximizes
the goodness of fit. While multiple arc changes are considered at each
step, arc reversal requires two steps. This implementation (in
<code>C</code>), which is more intuitive with a pre-computed cache of
local scores, is optimized for the <code>abn</code> workflow. For
details see the help page of <code>searchHillClimber()</code>.</p></li>
<li><p><code>searchHeuristic()</code>: This function is a flexible
implementation of multiple greedy heuristic algorithms, particularly
well adapted to the <code>abn</code> framework. It targets multi-random
restarts heuristic algorithms and allows the user to select the number
of searches and the maximum number of steps within each search. The
function implements three algorithms selected with the parameter
<code>algo</code>: <code>hc</code>, <code>tabu</code>, or
<code>sa</code>.</p>
<ul>
<li><p><code>algo=hc</code>: This alternative implementation of the
greedy hill-climbing approach that is fully written in R, unlike
<code>searchHillClimber()</code> and <code>mostProbable()</code> which
are written in <code>C</code>. It performs a local stepwise
optimization, choosing a structural move and computing the score’s
change. This function is closer to the MCMCMC algorithm from <span class="citation">Madigan, York, and Allard (1995)</span> and <span class="citation">Paolo Giudici and Roberto Castello (2003)</span> with a
single edge move.</p></li>
<li><p><code>algo=tabu</code>: The same algorithm as <code>hc</code> is
used, but a list of banned moves is computed. The parameter
<code>tabu.memory</code> controls the length of the tabu list. This
forces the algorithm to escape the local maximum by choosing some not
already used moves.</p></li>
<li><p><code>algo=sa</code>: This variant of the heuristic search
algorithm is based on simulated annealing described by <span class="citation">Metropolis et al. (1953)</span>. Some accepted moves
could result in a decrease of the network score. The acceptance rate can
be monitored with the parameter <code>temperature</code>.</p></li>
</ul></li>
</ul>
<p>For more information, refer to the help page
<code>searchHeuristic()</code>.</p>
</div>
<div id="references" class="section level1">
<h1>References</h1>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-heckerman_learning_1995" class="csl-entry">
Heckerman, David, Dan Geiger, and David M. Chickering. 1995.
<span>“Learning <span>Bayesian</span> <span>Networks</span>:
<span>The</span> <span>Combination</span> of <span>Knowledge</span> and
<span>Statistical</span> <span>Data</span>.”</span> <em>Machine
Learning</em> 20 (3): 197–243. <a href="https://doi.org/10.1023/A:1022623210503">https://doi.org/10.1023/A:1022623210503</a>.
</div>
<div id="ref-koivisto_exact_2004" class="csl-entry">
Koivisto, Mikko, and Kismat Sood. 2004. <span>“Exact
<span>Bayesian</span> <span>Structure</span> <span>Discovery</span> in
<span>Bayesian</span> <span>Networks</span>.”</span> <em>Journal of
Machine Learning Research</em>, 25.
</div>
<div id="ref-koller_probabilistic_2009" class="csl-entry">
Koller, Daphne, and Nir Friedman. 2009. <em>Probabilistic Graphical
Models: Principles and Techniques</em>. Adaptive Computation and Machine
Learning. Cambridge, MA: MIT Press.
</div>
<div id="ref-madigan_bayesian_1995" class="csl-entry">
Madigan, David, Jeremy York, and Denis Allard. 1995. <span>“Bayesian
<span>Graphical</span> <span>Models</span> for <span>Discrete</span>
<span>Data</span>.”</span> <em>International Statistical Review / Revue
Internationale de Statistique</em> 63 (2): 215. <a href="https://doi.org/10.2307/1403615">https://doi.org/10.2307/1403615</a>.
</div>
<div id="ref-metropolis_equation_1953" class="csl-entry">
Metropolis, Nicholas, Arianna W. Rosenbluth, Marshall N. Rosenbluth,
Augusta H. Teller, and Edward Teller. 1953. <span>“Equation of
<span>State</span> <span>Calculations</span> by <span>Fast</span>
<span>Computing</span> <span>Machines</span>.”</span> <em>The Journal of
Chemical Physics</em> 21 (6): 1087–92. <a href="https://doi.org/10.1063/1.1699114">https://doi.org/10.1063/1.1699114</a>.
</div>
<div id="ref-paolo_giudici_improving_2003" class="csl-entry">
Paolo Giudici, and Roberto Castello. 2003. <span>“Improving
<span>Markov</span> <span>Chain</span> <span>Monte</span>
<span>Carlo</span> <span>Model</span> <span>Search</span> for
<span>Data</span> <span>Mining</span>.”</span> <em>Machine Learning</em>
50: 32.
</div>
</div>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
